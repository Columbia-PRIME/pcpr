<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Square root principal component pursuit (convex PCP) — root_pcp • pcpr</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><script src="../deps/MathJax-3.2.2/tex-chtml.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Square root principal component pursuit (convex PCP) — root_pcp"><meta name="description" content="root_pcp() implements the convex PCP algorithm &quot;Square root principal
component pursuit&quot; as described in
Zhang et al. (2021)
, outfitted with environmental health (EH)-specific extensions as described
in Gibson et al. (2022).
Given an observed data matrix D, and regularization parameters lambda and
mu, root_pcp() aims to find the best low-rank and sparse estimates L
and S. The L matrix encodes latent patterns that govern the observed
data. The S matrix captures any extreme events in the data unexplained by
the underlying patterns in L.
Being convex, root_pcp() determines the rank r, or number of latent
patterns in the data, autonomously during it's optimization. As such, the
user does not need to specify the desired rank r of the output L matrix
as in the non-convex PCP model rrmc().
Experimentally, the root_pcp() approach to PCP modeling has best been able
to handle those datasets that are governed by well-defined underlying
patterns, characterized by quickly decaying singular values. This is typical
of imaging and video data, but uncommon for EH data. For observed data with a
complex low rank structure (slowly decaying singular values), like EH data,
rrmc() may offer a better model estimate.
Three EH-specific extensions are currently supported by root_pcp():
The model can handle missing values in the input data matrix D;
The model can also handle measurements that fall below the limit of
detection (LOD), if provided LOD information by the user; and
The model is also equipped with an optional non-negativity constraint
on the low-rank L matrix, ensuring that all output values in L are
\(&amp;gt; 0\).

"><meta property="og:description" content="root_pcp() implements the convex PCP algorithm &quot;Square root principal
component pursuit&quot; as described in
Zhang et al. (2021)
, outfitted with environmental health (EH)-specific extensions as described
in Gibson et al. (2022).
Given an observed data matrix D, and regularization parameters lambda and
mu, root_pcp() aims to find the best low-rank and sparse estimates L
and S. The L matrix encodes latent patterns that govern the observed
data. The S matrix captures any extreme events in the data unexplained by
the underlying patterns in L.
Being convex, root_pcp() determines the rank r, or number of latent
patterns in the data, autonomously during it's optimization. As such, the
user does not need to specify the desired rank r of the output L matrix
as in the non-convex PCP model rrmc().
Experimentally, the root_pcp() approach to PCP modeling has best been able
to handle those datasets that are governed by well-defined underlying
patterns, characterized by quickly decaying singular values. This is typical
of imaging and video data, but uncommon for EH data. For observed data with a
complex low rank structure (slowly decaying singular values), like EH data,
rrmc() may offer a better model estimate.
Three EH-specific extensions are currently supported by root_pcp():
The model can handle missing values in the input data matrix D;
The model can also handle measurements that fall below the limit of
detection (LOD), if provided LOD information by the user; and
The model is also equipped with an optional non-negativity constraint
on the low-rank L matrix, ensuring that all output values in L are
\(&amp;gt; 0\).

"><meta property="og:image" content="https://columbia-prime.github.io/pcpr/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pcpr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/pcp-applied.html">Air pollution source apportionment with PCP</a></li>
    <li><a class="dropdown-item" href="../articles/pcp-quickstart.html">Quickstart: applying PCP to a simulated environmental mixture</a></li>
    <li><a class="dropdown-item" href="../articles/theory-crash-course.html">Theory crash course</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Columbia-PRIME/pcpr/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Square root principal component pursuit (convex PCP)</h1>
      <small class="dont-index">Source: <a href="https://github.com/Columbia-PRIME/pcpr/blob/main/R/root_pcp.R" class="external-link"><code>R/root_pcp.R</code></a></small>
      <div class="d-none name"><code>root_pcp.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>root_pcp()</code> implements the convex PCP algorithm "Square root principal
component pursuit" as described in
<a href="https://proceedings.neurips.cc/paper/2021/hash/f65854da4622c1f1ad4ffeb361d7703c-Abstract.html" class="external-link">Zhang et al. (2021)</a>
, outfitted with environmental health (EH)-specific extensions as described
in Gibson et al. (2022).</p>
<p>Given an observed data matrix <code>D</code>, and regularization parameters <code>lambda</code> and
<code>mu</code>, <code>root_pcp()</code> aims to find the best low-rank and sparse estimates <code>L</code>
and <code>S</code>. The <code>L</code> matrix encodes latent patterns that govern the observed
data. The <code>S</code> matrix captures any extreme events in the data unexplained by
the underlying patterns in <code>L</code>.</p>
<p>Being convex, <code>root_pcp()</code> determines the rank <code>r</code>, or number of latent
patterns in the data, autonomously during it's optimization. As such, the
user does not need to specify the desired rank <code>r</code> of the output <code>L</code> matrix
as in the non-convex PCP model <code><a href="rrmc.html">rrmc()</a></code>.</p>
<p>Experimentally, the <code>root_pcp()</code> approach to PCP modeling has best been able
to handle those datasets that are governed by well-defined underlying
patterns, characterized by quickly decaying singular values. This is typical
of imaging and video data, but uncommon for EH data. For observed data with a
complex low rank structure (slowly decaying singular values), like EH data,
<code><a href="rrmc.html">rrmc()</a></code> may offer a better model estimate.</p>
<p>Three EH-specific extensions are currently supported by <code>root_pcp()</code>:</p><ol><li><p>The model can handle missing values in the input data matrix <code>D</code>;</p></li>
<li><p>The model can also handle measurements that fall below the limit of
detection (LOD), if provided <code>LOD</code> information by the user; and</p></li>
<li><p>The model is also equipped with an optional non-negativity constraint
on the low-rank <code>L</code> matrix, ensuring that all output values in <code>L</code> are
\(&gt; 0\).</p></li>
</ol></div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">root_pcp</span><span class="op">(</span></span>
<span>  <span class="va">D</span>,</span>
<span>  lambda <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  mu <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  LOD <span class="op">=</span> <span class="op">-</span><span class="cn">Inf</span>,</span>
<span>  non_negative <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  max_iter <span class="op">=</span> <span class="fl">10000</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-d">D<a class="anchor" aria-label="anchor" href="#arg-d"></a></dt>
<dd><p>The input data matrix (can contain <code>NA</code> values). Note that PCP will
converge much more quickly when <code>D</code> has been standardized in some way (e.g.
scaling columns by their standard deviations, or column-wise min-max
normalization).</p></dd>


<dt id="arg-lambda-mu">lambda, mu<a class="anchor" aria-label="anchor" href="#arg-lambda-mu"></a></dt>
<dd><p>(Optional) A pair of doubles each in the range <code>[0, Inf)</code>
regularizing <code>S</code> and <code>L</code>. <code>lambda</code> controls the sparsity of the output
<code>S</code> matrix; larger values penalize non-zero entries in <code>S</code> more
stringently, driving the recovery of sparser <code>S</code> matrices. <code>mu</code> adjusts the
model's sensitivity to noise; larger values will penalize errors between
the predicted model and the observed data more severely. It is highly
recommended the user tunes both of these parameters using
<code><a href="grid_search_cv.html">grid_search_cv()</a></code> for each unique data matrix <code>D</code>. By default, both
<code>lambda</code> and <code>mu</code> are <code>NULL</code>, in which case the theoretically optimal
values are used, calculated according to <code><a href="get_pcp_defaults.html">get_pcp_defaults()</a></code>.</p></dd>


<dt id="arg-lod">LOD<a class="anchor" aria-label="anchor" href="#arg-lod"></a></dt>
<dd><p>(Optional) The limit of detection (LOD) data. Entries in <code>D</code> that
satisfy <code>D &gt;= LOD</code> are understood to be above the LOD, otherwise those
entries are treated as below the LOD. <code>LOD</code> can be either:</p><ul><li><p>A double, implying a universal LOD common across all measurements in <code>D</code>;</p></li>
<li><p>A vector of length <code>ncol(D)</code>, signifying a column-specific LOD, where
each entry in the <code>LOD</code> vector corresponds to the LOD for each column in
<code>D</code>; or</p></li>
<li><p>A matrix of dimension <code>dim(D)</code>, indicating an observation-specific LOD,
where each entry in the <code>LOD</code> matrix corresponds to the LOD for each
entry in <code>D</code>.</p></li>
</ul><p>By default, <code>LOD = -Inf</code>, indicating there are no known LODs for PCP to
leverage.</p></dd>


<dt id="arg-non-negative">non_negative<a class="anchor" aria-label="anchor" href="#arg-non-negative"></a></dt>
<dd><p>(Optional) A logical indicating whether or not the
non-negativity constraint should be used to constrain the output <code>L</code>
matrix to have all entries \(\geq 0\). By default, <code>non_negative = TRUE</code>.</p></dd>


<dt id="arg-max-iter">max_iter<a class="anchor" aria-label="anchor" href="#arg-max-iter"></a></dt>
<dd><p>(Optional) An integer specifying the maximum number of
iterations to allow PCP before giving up on meeting PCP's convergence
criteria. By default, <code>max_iter = 10000</code>, suitable for most problems.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>(Optional) A logical indicating whether or not to print
information in real time over the course of PCP's optimization. By
default, <code>verbose = FALSE</code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><ul><li><p><code>L</code>: The rank-<code>r</code> low-rank matrix encoding the <code>r</code>-many latent patterns
governing the observed input data matrix <code>D</code>. <code>dim(L)</code> will be the same
as <code>dim(D)</code>. To explicitly obtain the underlying patterns, <code>L</code> can be
used as the input to any matrix factorization technique of choice, e.g.
PCA, factor analysis, or non-negative matrix factorization.</p></li>
<li><p><code>S</code>: The sparse matrix containing the rare outlying or extreme
observations in <code>D</code> that are not explained by the underlying patterns in
the corresponding <code>L</code> matrix. <code>dim(S)</code> will be the same as <code>dim(D)</code>.
Most entries in <code>S</code> are <code>0</code>, while non-zero entries identify the extreme
outlying observations in <code>D</code>.</p></li>
<li><p><code>num_iter</code>: The number of iterations taken to reach convergence. If
<code>num_iter == max_iter</code> then <code>root_pcp()</code> did not converge.</p></li>
<li><p><code>objective</code>: A vector containing the values of <code>root_pcp()</code>'s objective
function over the course of optimization.</p></li>
<li><p><code>converged</code>: A boolean indicating whether the convergence criteria were
met before <code>max_iter</code> was reached.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="the-objective-function">The objective function<a class="anchor" aria-label="anchor" href="#the-objective-function"></a></h2>


<p><code>root_pcp()</code> optimizes the following objective function:
$$\min_{L, S} ||L||_* + \lambda ||S||_1 + \mu ||L + S - D||_F$$
The first term is the nuclear norm of the <code>L</code> matrix, incentivizing <code>L</code> to be
low-rank. The second term is the \(\ell_1\) norm of the <code>S</code> matrix,
encouraging <code>S</code> to be sparse. The third term is the Frobenius norm
applied to the model's noise, ensuring that the estimated low-rank and sparse
models <code>L</code> and <code>S</code> together have high fidelity to the observed data <code>D</code>.
The objective is not smooth nor differentiable, however it is convex and
separable. As such, it is optimized using the Alternating Direction
Method of Multipliers (ADMM) algorithm Boyd et al. (2011), Gao et al. (2020).</p>
    </div>
    <div class="section level2">
    <h2 id="the-lambda-and-mu-parameters">The <code>lambda</code> and <code>mu</code> parameters<a class="anchor" aria-label="anchor" href="#the-lambda-and-mu-parameters"></a></h2>


<ul><li><p><code>lambda</code> controls the sparsity of <code>root_pcp()</code>'s output <code>S</code> matrix;
larger values of <code>lambda</code> penalize non-zero entries in <code>S</code> more
stringently, driving the recovery of sparser <code>S</code> matrices. Therefore,
if you a priori expect few outlying events in your model, you might
expect a grid search to recover relatively larger <code>lambda</code> values, and
vice-versa.</p></li>
<li><p><code>mu</code> adjusts <code>root_pcp()</code>'s sensitivity to noise; larger values of <code>mu</code>
penalize errors between the predicted model and the observed data (i.e.
noise), more severely. Environmental data subject to higher noise levels
therefore require a <code>root_pcp()</code> model equipped with smaller <code>mu</code> values
(since higher noise means a greater discrepancy between the observed
mixture and the true underlying low-rank and sparse model). In virtually
noise-free settings (e.g. simulations), larger values of <code>mu</code> would be
appropriate.</p></li>
</ul><p>The default values of <code>lambda</code> and <code>mu</code> offer <em>theoretical</em> guarantees
of optimal estimation performance, and stable recovery of <code>L</code> and <code>S</code>. By
"stable", we mean <code>root_pcp()</code>'s reconstruction error is, in the worst case,
proportional to the magnitude of the noise corrupting the observed data
(\(||Z||_F\)), often outperforming this upper bound.
Candès et al. (2011) obtained the guarantee for <code>lambda</code>, while
<a href="https://proceedings.neurips.cc/paper/2021/hash/f65854da4622c1f1ad4ffeb361d7703c-Abstract.html" class="external-link">Zhang et al. (2021)</a>
obtained the result for <code>mu</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="environmental-health-specific-extensions">Environmental health specific extensions<a class="anchor" aria-label="anchor" href="#environmental-health-specific-extensions"></a></h2>


<p>We refer interested readers to
Gibson et al. (2022) for the complete details regarding the EH-specific
extensions.</p>
<p><strong>Missing value functionality:</strong> PCP assumes that the same data generating
mechanisms govern both the missing and the observed entries in <code>D</code>. Because
PCP primarily seeks accurate estimation of <em>patterns</em> rather than
individual <em>observations</em>, this assumption is reasonable, but in some edge
cases may not always be justified. Missing values in <code>D</code> are therefore
reconstructed in the recovered low-rank <code>L</code> matrix according to the
underlying patterns in <code>L</code>. There are three corollaries to keep in mind
regarding the quality of recovered missing observations:</p><ol><li><p>Recovery of missing entries in <code>D</code> relies on accurate estimation of
<code>L</code>;</p></li>
<li><p>The fewer observations there are in <code>D</code>, the harder it is to accurately
reconstruct <code>L</code> (therefore estimation of <em>both</em> unobserved <em>and</em> observed
measurements in <code>L</code> degrades); and</p></li>
<li><p>Greater proportions of missingness in <code>D</code> artifically drive up the
sparsity of the estimated <code>S</code> matrix. This is because it is not possible
to recover a sparse event in <code>S</code> when the corresponding entry in <code>D</code> is
unobserved. By definition, sparse events in <code>S</code> cannot be explained by
the consistent patterns in <code>L</code>. Practically, if 20% of the entries in <code>D</code>
are missing, then at least 20% of the entries in <code>S</code> will be 0.</p></li>
</ol><p><strong>Handling measurements below the limit of detection:</strong> When equipped with
LOD information, PCP treats any estimations of values known to be below the
LOD as equally valid if their approximations fall between 0 and the LOD. Over
the course of optimization, observations below the LOD are pushed into this
known range \([0, LOD]\) using penalties from above and below: should a
\(&lt; LOD\) estimate be \(&lt; 0\), it is stringently penalized, since
measured observations cannot be negative. On the other hand, if a \(&lt; LOD\)
estimate is \(&gt;\) the LOD, it is also heavily penalized: less so than when
\(&lt; 0\), but more so than observations known to be above the LOD, because
we have prior information that these observations must be below LOD.
Observations known to be above the LOD are penalized as usual, using the
Frobenius norm in the above objective function.</p>
<p>Gibson et al. (2022) demonstrates that
in experimental settings with up to 50% of the data corrupted below the LOD,
PCP with the LOD extension boasts superior accuracy of recovered <code>L</code> models
compared to PCA coupled with \(LOD / \sqrt{2}\) imputation. PCP even
outperforms PCA in low-noise scenarios with as much as 75% of the data
corrupted below the LOD. The few situations in which PCA bettered PCP were
those pathological cases in which <code>D</code> was characterized by extreme noise and
huge proportions (i.e., 75%) of observations falling below the LOD.</p>
<p><strong>The non-negativity constraint on <code>L</code>:</strong> To enhance interpretability of
PCP-rendered solutions, there is an optional non-negativity constraint
that can be imposed on the <code>L</code> matrix to ensure all estimated values
within it are \(\geq 0\). This prevents researchers from having to deal
with negative observation values and questions surrounding their meaning
and utility. Non-negative <code>L</code> models also allow for seamless use of methods
such as non-negative matrix factorization to extract non-negative patterns.
The non-negativity constraint is incorporated in the ADMM splitting technique
via the introduction of an additional optimization variable and corresponding
constraint.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Zhang, Junhui, Jingkai Yan, and John Wright.
"Square root principal component pursuit: tuning-free noisy robust matrix
recovery." Advances in Neural Information Processing Systems 34 (2021):
29464-29475. [available
<a href="https://proceedings.neurips.cc/paper/2021/hash/f65854da4622c1f1ad4ffeb361d7703c-Abstract.html" class="external-link">here</a>]</p>
<p>Gibson, Elizabeth A., Junhui Zhang, Jingkai Yan, Lawrence
Chillrud, Jaime Benavides, Yanelli Nunez, Julie B. Herbstman, Jeff
Goldsmith, John Wright, and Marianthi-Anna Kioumourtzoglou.
"Principal component pursuit for pattern identification in
environmental mixtures." Environmental Health Perspectives 130, no.
11 (2022): 117008.</p>
<p>Boyd, Stephen, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan
Eckstein. "Distributed optimization and statistical learning via the
alternating direction method of multipliers." Foundations and Trends in
Machine learning 3, no. 1 (2011): 1-122.</p>
<p>Gao, Wenbo, Donald Goldfarb, and Frank E. Curtis. "ADMM for
multiaffine constrained optimization." Optimization Methods and Software
35, no. 2 (2020): 257-303.</p>
<p>Candès, Emmanuel J., Xiaodong Li, Yi Ma, and John Wright.
"Robust principal component analysis?." Journal of the ACM (JACM)
58, no. 3 (2011): 1-37.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="rrmc.html">rrmc()</a></code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co">#### -------Simple simulated PCP problem-------####</span></span></span>
<span class="r-in"><span><span class="co"># First we will simulate a simple dataset with the sim_data() function.</span></span></span>
<span class="r-in"><span><span class="co"># The dataset will be a 100x10 matrix comprised of:</span></span></span>
<span class="r-in"><span><span class="co"># 1. A rank-2 component as the ground truth L matrix;</span></span></span>
<span class="r-in"><span><span class="co"># 2. A ground truth sparse component S w/outliers along the diagonal; and</span></span></span>
<span class="r-in"><span><span class="co"># 3. A dense Gaussian noise component</span></span></span>
<span class="r-in"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="sim_data.html">sim_data</a></span><span class="op">(</span>r <span class="op">=</span> <span class="fl">2</span>, sigma <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># Best practice is to conduct a grid search with grid_search_cv() function,</span></span></span>
<span class="r-in"><span><span class="co"># but we skip that here for brevity.</span></span></span>
<span class="r-in"><span><span class="va">pcp_model</span> <span class="op">&lt;-</span> <span class="fu">root_pcp</span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">D</span>, lambda <span class="op">=</span> <span class="fl">0.225</span>, mu <span class="op">=</span> <span class="fl">3.04</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="st">"Estimated_L_rank"</span> <span class="op">=</span> <span class="fu"><a href="matrix_rank.html">matrix_rank</a></span><span class="op">(</span><span class="va">pcp_model</span><span class="op">$</span><span class="va">L</span>, <span class="fl">5e-2</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="st">"Observed_relative_error"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span> <span class="op">-</span> <span class="va">data</span><span class="op">$</span><span class="va">D</span>, <span class="st">"F"</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span>, <span class="st">"F"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="st">"PCA_error"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span> <span class="op">-</span> <span class="fu"><a href="proj_rank_r.html">proj_rank_r</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">D</span>, r <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>, <span class="st">"F"</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span>, <span class="st">"F"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="st">"PCP_L_error"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span> <span class="op">-</span> <span class="va">pcp_model</span><span class="op">$</span><span class="va">L</span>, <span class="st">"F"</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">L</span>, <span class="st">"F"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="st">"PCP_S_error"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">S</span> <span class="op">-</span> <span class="va">pcp_model</span><span class="op">$</span><span class="va">S</span>, <span class="st">"F"</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/norm.html" class="external-link">norm</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">S</span>, <span class="st">"F"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   Estimated_L_rank Observed_relative_error PCA_error PCP_L_error PCP_S_error</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1                2               0.2298567 0.1040869  0.09485763   0.2453499</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://lawrence-chillrud.github.io/" class="external-link">Lawrence G. Chillrud</a>, <a href="https://www.linkedin.com/in/jaime-benavides-72959356/" class="external-link">Jaime Benavides</a>, <a href="https://lizzy.codes/index.html" class="external-link">Elizabeth A. Gibson</a>, <a href="https://scholar.google.com/citations?user=LyLU8koAAAAJ&amp;hl=en" class="external-link">Junhui Zhang</a>, <a href="https://www.linkedin.com/in/jingkai-yan-a49a9516a/" class="external-link">Jingkai Yan</a>, <a href="https://www.columbia.edu/~jw2966/" class="external-link">John N. Wright</a>, <a href="https://jeffgoldsmith.com/" class="external-link">Jeff Goldsmith</a>, <a href="https://marianthi.github.io/makLAB.github.io/" class="external-link">Marianthi-Anna Kioumourtzoglou</a>, <a href="https://www.publichealth.columbia.edu/" class="external-link"><img src="https://www.publichealth.columbia.edu/sites/default/files/logo-mailman-blue-horizontal.svg?stefxf" width="240" alt=""></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

