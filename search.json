[{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://columbia-prime.github.io/pcpr/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"exploring-the-raw-data","dir":"Articles","previous_headings":"Preprocessing","what":"Exploring the raw data","title":"Air pollution source apportionment with PCP","text":"start examining raw queens data: Let’s visualize data heatmap using plot_matrix() function wrote :  Clearly scale chemical differs widely. Let’s now visualize measured chemical species timeseries get better sense ’re dealing . Plotted black raw observed PM\\(_{2.5}\\) measurements (µg/m\\(^3\\)) time (04/04/2001 - 12/30/2021), plotted red (rough) lines best fit:  initial points make note , looking data: saw heatmap, scale chemical’s measured concentration differs widely (e.g., NH4 ranges 0 9 µg/m\\(^3\\), Ti ranges 0 0.04 µg/m\\(^3\\)). correct moment preprocess data. chemical species record negative measurements (e.g., Al, Ba, Cd). explained EPA AQS data documentation, due idiosyncrasies instruments used collect measurements. zero negative measurements preprocessing. can see strong seasonal trends species (e.g., NO3), well reduction concentration time others (e.g., Ni). Many species prominent outliers, extreme exposure events (e.g., Cr, Cu). , species extreme exposure events following seasonal trends, e.g., K. Elemental carbon (EC) organic carbon (OC) missing measurements first 8 years dataset, likely air monitors two species operational 2001 - 2009. Handling systematic missingness scope tutorial. remove measurements made 2015, yielding queens_small dataset use moving forward. make decision prior knowledge years leading 2015, gradually, many Midwestern coal-fired power plants closed, reducing regional / secondary signal experienced downwind Queens, NYC 2015 (Hopke et al. (2024)). interested looking trends data (soft) change. Next, let’s take look correlation structure raw queens_small data:  noisy measurements high dimensionality queens_small air pollution mixture matrix gives rise relatively complex correlation matrix. strong patterns jump right away . ’d like employ PCP order reduce complexity data - handling noise outliers - robust downstream analysis. Keep correlation matrix mind, since applying PCP, ’ll examine correlation matrix recovered L matrix compare.","code":"queens #> # A tibble: 2,443 × 27 #>    Date            Al   NH4      As     Ba       Br     Cd      Ca      Cl #>    <date>       <dbl> <dbl>   <dbl>  <dbl>    <dbl>  <dbl>   <dbl>   <dbl> #>  1 2001-04-04 NA      1.62  NA      NA     NA       NA     NA      NA      #>  2 2001-04-07  0      2.66   0       0.012  0.00488  0      0.0401  0.0079 #>  3 2001-04-13  0.0094 1.41   0.0016  0.024  0.00211  0.004  0.036   0      #>  4 2001-04-19  0.0104 1.22   0.001   0.006  0.00422  0      0.0543  0.003  #>  5 2001-04-25  0.0172 0.723  0.0024  0.015  0.00117  0      0.0398  0      #>  6 2001-05-01  0.0384 3.48   0.0017  0.041  0.00873  0.001  0.136   0      #>  7 2001-05-04  0.0964 6.22   0.0025  0.039  0.0111   0      0.137   0      #>  8 2001-05-07  0.004  0.233  0.001   0.016  0.00263  0      0.055   0.0054 #>  9 2001-05-10  0.0547 2.04   0.001   0.055  0.00521  0      0.121   0.001  #> 10 2001-05-13  0.0215 0.229  0       0.021  0.00122  0      0.0249  0      #> # ℹ 2,433 more rows #> # ℹ 18 more variables: Cr <dbl>, Cu <dbl>, EC <dbl>, Fe <dbl>, Pb <dbl>, #> #   Mg <dbl>, Mn <dbl>, Ni <dbl>, OC <dbl>, K <dbl>, Se <dbl>, Si <dbl>, #> #   Na <dbl>, S <dbl>, Ti <dbl>, NO3 <dbl>, V <dbl>, Zn <dbl> plot_matrix(queens[, 2:ncol(queens)]) queens %>%   pivot_longer(     colnames(queens)[-1],     names_to = \"chem\", values_to = \"concentration\"   ) %>%   filter(!is.na(concentration)) %>%   ggplot(aes(x = Date, y = concentration)) +   geom_line() +   geom_smooth(color = \"red\", formula = \"y ~ x\", method = \"loess\", span = 0.05) +   facet_wrap(~chem, scales = \"free_y\") +   labs(x = \"Date\", y = \"Concentration (µg/m^3)\") +   theme_bw() start_date <- \"2015-01-01\" queens_small <- queens %>% filter(Date >= as.Date(start_date)) queens_small #> # A tibble: 838 × 27 #>    Date           Al   NH4     As     Ba      Br     Cd      Ca      Cl     Cr #>    <date>      <dbl> <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 2015-01-03  0     0.439  0      0      0.003   0      0.0336  0.0168  0.005 #>  2 2015-01-06  0     1.2    0      0.005  0.0041  0      0.0522  0.0716  0     #>  3 2015-01-09 NA     0.911 NA     NA     NA      NA     NA      NA      NA     #>  4 2015-01-12  0.014 1.21   0.001  0.016  0.0075  0      0.0651  0.134   0     #>  5 2015-01-15  0.016 2.28   0      0.012  0.0054  0      0.0798  0.142   0     #>  6 2015-01-18  0     0.365  0      0.001  0.002   0      0.0569  0.159   0     #>  7 2015-01-21  0     0.496  0      0      0.0027  0      0.0334  0.0428  0     #>  8 2015-01-24  0     1.66   0      0      0.0046  0.007  0.0293  0.0275  0     #>  9 2015-01-27  0     0.281  0      0      0.001   0      0.0298  0.0325  0     #> 10 2015-01-30  0.005 1.07   0      0.017  0.0018  0      0.0614  0.0633  0.003 #> # ℹ 828 more rows #> # ℹ 17 more variables: Cu <dbl>, EC <dbl>, Fe <dbl>, Pb <dbl>, Mg <dbl>, #> #   Mn <dbl>, Ni <dbl>, OC <dbl>, K <dbl>, Se <dbl>, Si <dbl>, Na <dbl>, #> #   S <dbl>, Ti <dbl>, NO3 <dbl>, V <dbl>, Zn <dbl> ggcorr(   queens_small[, 2:ncol(queens_small)],   method = \"pairwise.complete.obs\",   limits = FALSE, label = FALSE, size = 5 )"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"data-standardization","dir":"Articles","previous_headings":"Preprocessing","what":"Data standardization","title":"Air pollution source apportionment with PCP","text":"able run PCP, need first preprocess data better numerical stability. Despite making minimal assumptions input data, PCP converges practice much quickly data standardized way. goal rescale data columns comparable scale without meaningfully altering original distributions columns. Let’s examine distributions queens_small dataset:  many choices ’d like preprocess data, e.g., standardize data, min-max normalization, etc. data appears normal, log normal, exponential. choose scale (center) PM\\(_2.5\\) species dataset (also choose set negative measurements 0 better interpretability):  ’s preprocessing! Now can turn attention PCP.","code":"queens_small %>%   pivot_longer(     colnames(queens_small)[-1],     names_to = \"chem\", values_to = \"concentration\"   ) %>%   filter(!is.na(concentration)) %>%   ggplot(aes(x = concentration)) +   geom_histogram(bins = 50) +   theme_bw() +   facet_wrap(~chem, scales = \"free\") queens_scaled <- queens_small %>% select(-Date) queens_scaled[queens_scaled < 0] <- 0  queens_scaled <- queens_scaled %>%   scale(center = FALSE) %>%   as_tibble()  queens_scaled$Date <- queens_small$Date  queens_scaled %>%   pivot_longer(     colnames(queens_small)[-1],     names_to = \"chem\", values_to = \"concentration\"   ) %>%   filter(!is.na(concentration)) %>%   ggplot(aes(x = concentration)) +   geom_histogram(bins = 50) +   theme_bw() +   facet_wrap(~chem, scales = \"free\")"},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"model-selection","dir":"Articles","previous_headings":"Principal component pursuit","what":"Model selection","title":"Air pollution source apportionment with PCP","text":"two PCP algorithms shipped pcpr: convex root_pcp() [Zhang et al. (2021)] non-convex rrmc() [Cherapanamjeri et al. (2017)]. rrmc() best suited data characterized slowly decaying singular values, indicative complex underlying patterns relatively large degree noise. EH data can described way. root_pcp() best data characterized rapidly decaying singular values, indicative well-defined latent patterns. figure model best data, let’s inspect singular values observed mixture using sing() method. PCP can handle NA values, sing() , quickly impute missing values corresponding column mean via impute_matrix() function:  singular values slowly decay, corroborating relatively complex underlying low-rank structure obscured high degree noise saw correlation matrix earlier. , move forward rrmc() PCP model.","code":"D <- as.matrix(queens_scaled %>% select(-Date)) D_imputed <- impute_matrix(D, apply(D, 2, mean, na.rm = TRUE)) singular_values <- sing(D_imputed) plot(singular_values, type = \"b\")"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"grid-search-for-parameter-tuning","dir":"Articles","previous_headings":"Principal component pursuit","what":"Grid search for parameter tuning","title":"Air pollution source apportionment with PCP","text":"estimate low-rank sparse matrices L S, rrmc() needs given maximum rank search r regularization parameter eta. determine optimal values r eta, conduct brief grid search using grid_search_cv() function. Recall rrmc() uses incremental rank-based procedure recovering L S: First, rank-\\(1\\) model \\((L^{(1)}, S^{(1)})\\) estimated. rank-\\(1\\) model used initialization point construct rank-\\(2\\) model \\((L^{(2)}, S^{(2)})\\), , desired rank-r model \\((L^{(r)}, S^{(r)})\\) recovered. models ranks \\(1\\) \\(r\\) returned rrmc() way. , can fix rank r gridsearch maximum rank like search . ’ve chosen \\(r = 8\\), since expect 8 distinct sources govern queens PM\\(_2.5\\) data 2015-2021 (based prior studies suggesting ~5 sources perhaps reasonable). also need tune eta parameter, ensuring also cover rough default value obtained via get_pcp_defaults(). eta parameter can thought dial controlling interplay low-rank L sparse S models. Larger values eta place greater emphasis penalizing non-zero entries S penalizing errors predicted observed data (dense noise \\(Z\\)). Note time need impute data chemical means, since like rrmc() recover missing NA values using low-rank structure present data. results search suggest rank 4 solution eta 0.1 optimal, lowest average relative recovery error held test sets (73.2% relative error). solution yields sparse matrix S sparsity 99.3%, meaning 0.7% values data flagged extreme, outlying exposure events. , use parameters moving forward.","code":"eta_0 <- get_pcp_defaults(D)$eta # to get progress bar, could wrap this # in a call to progressr::with_progress({ gs <- grid_search_cv(...) }) gs <- grid_search_cv(   D,   pcp_fn = rrmc,   grid = data.frame(eta = 10^seq(-1, 2, 1) * round(eta_0, 3)),   r = 8,   parallel_strategy = \"multisession\",   num_workers = 16,   verbose = FALSE ) r_star <- gs$summary_stats$r[1] eta_star <- round(gs$summary_stats$eta[1], 3) gs$summary_stats #> # A tibble: 32 × 7 #>      eta     r rel_err L_rank S_sparsity iterations run_error_perc #>    <dbl> <int>   <dbl>  <dbl>      <dbl>      <dbl> <chr>          #>  1  0.1      4   0.732      4      0.993        NaN 0%             #>  2  0.1      3   0.733      3      0.995        NaN 0%             #>  3  0.1      2   0.752      2      0.993        NaN 0%             #>  4  0.1      1   0.756      1      0.991        NaN 0%             #>  5  1        1   0.756      1      1            NaN 0%             #>  6  1        2   0.760      2      1            NaN 0%             #>  7  1        3   0.805      3      1            NaN 0%             #>  8  0.01     7   0.806      1      0.173        NaN 0%             #>  9  0.01     8   0.806      1      0.173        NaN 0%             #> 10  0.01     5   0.806      1      0.173        NaN 0%             #> # ℹ 22 more rows"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"running-pcp","dir":"Articles","previous_headings":"Principal component pursuit","what":"Running PCP","title":"Air pollution source apportionment with PCP","text":"Now can run PCP model! can inspect evolution objective function course PCP’s optimization:","code":"pcp_model <- rrmc(D, r = r_star, eta = eta_star) L <- pcp_model$L S <- pcp_model$S plot(pcp_model$objective, type = \"l\")"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"the-recovered-l-matrix","dir":"Articles","previous_headings":"Principal component pursuit","what":"The recovered L matrix","title":"Air pollution source apportionment with PCP","text":"output L matrix:  Recall original correlation matrix queens_small :  new correlation matrix recovered L matrix now:  can see, PCP successfully reduced dimensionality data. underlying correlation structure now made much explicit.","code":"plot_matrix(L) L_rank <- matrix_rank(L) L_rank #> [1] 4 ggcorr(   queens_small[, 2:ncol(queens_small)],   method = \"pairwise.complete.obs\",   limits = FALSE, label = FALSE, size = 5 ) L_df <- data.frame(L) colnames(L_df) <- colnames(queens[, 2:ncol(queens)]) ggcorr(   L_df, method = \"pairwise.complete.obs\",   limits = FALSE, label = FALSE, size = 5 )"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"the-recovered-s-matrix","dir":"Articles","previous_headings":"Principal component pursuit","what":"The recovered S matrix","title":"Air pollution source apportionment with PCP","text":"Let’s briefly inspect PCP’s estimate sparse matrix S associated sparsity via sparsity():   can examine chemicals largest number outlying exposure events calculating sparsity column S: can see ammonium (NH4), silicon (Si), nitrate (NO3) extreme exposure events. Arsenic (), vanadium (V), selenium (Se) greatest number outlying events. can examine extreme events individual chemical : Let’s check another example, time examining sparse events isolated potassium (K), associated biomass burning fireworks. PCP able pick extreme potassium events around July 4th holiday July 4th / 5th dates available dataset (recall chemical concentrations recorded queens every three six days, skipping measurements July 4/5 years). dimensionality reduction techniques PCA can sensitive outliers, requiring researchers manually remove outlying events data. introduces subjectivity data preprocessing pipeline, researcher must define criteria removal, turn making downstream results less replicable. ’re now ready finish source apportionment using estimated low-rank L matrix.","code":"sparsity(S) #> [1] 0.9903158 hist(S) plot_matrix(S) S_df <- data.frame(S) colnames(S_df) <- colnames(queens_small[, 2:ncol(queens_small)]) chems_w_most_extreme_events <- sort(apply(S_df, 2, function(x) sparsity(as.matrix(x)))) chems_w_most_extreme_events #>        As         V        Se        Cd        Cr        Mn        Br        Ni  #> 0.9463007 0.9570406 0.9630072 0.9832936 0.9856802 0.9868735 0.9892601 0.9904535  #>        Cu         K        Mg        Ba        Zn        EC         S        Ca  #> 0.9928401 0.9928401 0.9940334 0.9952267 0.9952267 0.9964200 0.9964200 0.9976134  #>        Cl        Fe        Pb        OC        Ti        Al        Na       NH4  #> 0.9976134 0.9976134 0.9976134 0.9976134 0.9976134 0.9988067 0.9988067 1.0000000  #>        Si       NO3  #> 1.0000000 1.0000000 S_df %>%   select(As) %>%   mutate(Date = queens_small$Date) %>%   filter(As > 0) #>          As       Date #> 1  2.364937 2015-02-17 #> 2  3.534791 2015-03-10 #> 3  3.599878 2015-05-24 #> 4  2.334847 2015-06-11 #> 5  2.413293 2015-06-26 #> 6  2.376219 2015-07-08 #> 7  2.422048 2015-07-17 #> 8  2.382859 2015-07-20 #> 9  2.376002 2015-08-16 #> 10 2.416011 2015-09-27 #> 11 2.439816 2015-10-03 #> 12 2.435049 2015-11-11 #> 13 3.638617 2015-11-20 #> 14 4.826222 2015-12-05 #> 15 4.903026 2015-12-26 #> 16 2.415675 2016-02-18 #> 17 3.645952 2016-02-27 #> 18 2.473993 2016-03-01 #> 19 5.981860 2016-03-07 #> 20 2.424804 2016-03-22 #> 21 2.466317 2016-04-09 #> 22 6.090851 2016-04-12 #> 23 4.905858 2016-05-24 #> 24 4.840294 2016-05-27 #> 25 4.870333 2016-06-02 #> 26 7.353784 2016-07-23 #> 27 3.669314 2016-07-26 #> 28 7.359874 2016-08-07 #> 29 2.424597 2016-08-16 #> 30 4.864877 2016-09-09 #> 31 2.439062 2016-09-15 #> 32 4.901796 2016-11-20 #> 33 3.566015 2017-01-16 #> 34 2.446319 2017-06-15 #> 35 3.672702 2017-06-27 #> 36 2.451782 2017-09-19 #> 37 4.832047 2017-12-15 #> 38 6.088596 2018-02-16 #> 39 3.655234 2018-03-03 #> 40 2.413371 2018-03-27 #> 41 3.647023 2018-04-08 #> 42 6.171601 2018-06-25 #> 43 7.254815 2018-07-01 #> 44 3.644576 2018-08-12 #> 45 6.069988 2018-08-27 S_df %>%   select(K) %>%   mutate(Date = queens_small$Date) %>%   filter(K > 0) #>           K       Date #> 1  9.427762 2015-07-05 #> 2  3.064908 2017-06-03 #> 3 12.804711 2018-07-04 #> 4  5.698263 2020-06-20 #> 5 14.986152 2020-07-05 #> 6  4.566127 2021-02-24"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"pcp-and-nmf-for-source-apportionment","dir":"Articles","previous_headings":"","what":"PCP and NMF for source apportionment","title":"Air pollution source apportionment with PCP","text":"use Non-negative Matrix Factorization (NMF) extract patterns (loadings) corresponding scores encoded L matrix. See NMF::nmf() details. Since determined L rank 4 PCP’s grid search, longer need worry rank use NMF step, need manually remove outliers, since PCP autonomously isolated sparse matrix S.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"non-negative-matrix-factorization","dir":"Articles","previous_headings":"PCP and NMF for source apportionment","what":"Non-negative matrix factorization","title":"Air pollution source apportionment with PCP","text":"","code":"library(NMF)  nmf_mat <- L nmf_mat[nmf_mat < 0] <- 0  res <- nmf(   nmf_mat, rank = L_rank,   method = \"offset\", nrun = 30,   seed = 0, .opt = \"vp16\" )  raw_scores <- basis(res) raw_loadings <- coef(res)"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"pcp-nmf-loadings","dir":"Articles","previous_headings":"PCP and NMF for source apportionment","what":"PCP-NMF Loadings","title":"Air pollution source apportionment with PCP","text":"Let’s inspect loadings obtained PCP-NMF model:  Pattern 1 appears linked traffic road-related sources, characterized elements barium, calcium, lead, indicating emissions brake wear, tire wear, construction activities Pattern 2 looks like crustal dust, marked elements like aluminum, calcium, silicon, titanium, iron, suggesting resuspension natural materials soil rock. Pattern 3 clearly salt, including sodium chloride magnesium chloride. Pattern 4 represents mix regional/secondary sources traffic/tailpipe emissions, characterized sulfur, ammonium, nitrate, organic carbon, zinc. pattern lacks clear regional signal suggests contributions regional/secondary sources tailpipe emissions.","code":"loadings <- data.frame(raw_loadings) colnames(loadings) <- colnames(L_df) loadings[[\"Pattern\"]] <- paste(\"Pattern\", 1:L_rank)  loadings %>%   pivot_longer(-Pattern, names_to = \"Chemical\", values_to = \"Loading\") %>%   ggplot(aes(x = Chemical, y = Loading)) +   geom_point(size = 3) +   geom_segment(aes(yend = 0, xend = Chemical), linewidth = 1.5) +   facet_wrap(~Pattern, scales = \"free_x\") +   theme_bw() +   theme(     strip.text.x = element_text(size = 14),     title = element_text(size = 18),     legend.position = \"none\",     axis.text.x = element_text(angle = 45, hjust = 1, size = 12),     strip.background = element_rect(fill = \"white\"),     axis.title.x = element_blank(),     axis.title.y = element_blank()   ) +   geom_hline(yintercept = 0, size = 0.2) +   ggtitle(\"PCP-NMF Chemical Loadings\") #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated."},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"variance-explained","dir":"Articles","previous_headings":"PCP and NMF for source apportionment","what":"Variance Explained","title":"Air pollution source apportionment with PCP","text":"Let’s calculate variance explained patterns using pattern scores next. reorder patterns appear according proportion variance explained.","code":"nmf_scores <- data.frame(raw_scores) colnames(nmf_scores) <- c(   \"Traffic\", \"Crustal Dust\", \"Salt\", \"Regional/Secondary & Tailpipe Emissions\" ) days_of_the_week <- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\") nmf_sources <- nmf_scores %>%   mutate(     Date = queens_scaled$Date,     DayofWeek = as.character(wday(Date, label = TRUE)),     DayofWeek = factor(DayofWeek, levels = days_of_the_week),   ) %>%   pivot_longer(     -c(Date, DayofWeek),     names_to = \"Pattern\",     values_to = \"Score\"   )  var_explained <- nmf_sources %>%   group_by(Pattern) %>%   summarize(patsum = sum(Score)) %>%   mutate(VarianceExplained = round(100 * patsum / sum(patsum), 1)) %>%   select(-patsum) %>%   arrange(desc(VarianceExplained)) %>%   mutate(PatName = paste(Pattern, paste0(\"(\", VarianceExplained, \"% Var Exp)\")))  var_explained %>% select(-PatName) #> # A tibble: 4 × 2 #>   Pattern                                 VarianceExplained #>   <chr>                                               <dbl> #> 1 Regional/Secondary & Tailpipe Emissions              34.7 #> 2 Traffic                                              30.6 #> 3 Crustal Dust                                         20.5 #> 4 Salt                                                 14.2  nmf_sources <- nmf_sources %>%   mutate(     Pattern = factor(       Pattern,       levels = as.character(var_explained$Pattern),       labels = as.character(var_explained$PatName)     )   )"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"loadings-replotted","dir":"Articles","previous_headings":"PCP and NMF for source apportionment","what":"Loadings replotted","title":"Air pollution source apportionment with PCP","text":"can now replot loadings proper pattern names:","code":"loadings %>%   mutate(Pattern = factor(     colnames(nmf_scores),     levels = as.character(var_explained$Pattern),     labels = as.character(var_explained$PatName)   )) %>%   pivot_longer(-Pattern, names_to = \"Chemical\", values_to = \"Loading\") %>%   ggplot(aes(x = Chemical, y = Loading, color = Pattern)) +   scale_color_brewer(palette = \"Set1\") +   geom_point(size = 3) +   geom_segment(aes(yend = 0, xend = Chemical), linewidth = 1.5) +   facet_wrap(~Pattern, scales = \"free_x\") +   theme_bw() +   theme(     strip.text.x = element_text(size = 14),     title = element_text(size = 18),     legend.position = \"none\",     axis.text.x = element_text(angle = 45, hjust = 1, size = 12),     strip.background = element_rect(fill = \"white\"),     axis.title.x = element_blank(),     axis.title.y = element_blank()   ) +   geom_hline(yintercept = 0, size = 0.2) +   ggtitle(\"PCP-NMF Loadings\")"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"pcp-nmf-scores","dir":"Articles","previous_headings":"PCP and NMF for source apportionment","what":"PCP-NMF Scores","title":"Air pollution source apportionment with PCP","text":"can examine scores time:  scores across seasons (“DJF” = Winter, “MAM” = Spring, “JJA” = Summer, “SON” = Autumn)  Scores across days week:  Scores weekday vs. weekend:  Pattern correlations:","code":"yr_num <- length(unique(year(nmf_sources$Date)))  ggplot(nmf_sources, aes(Date, Score, color = Pattern)) +   scale_color_brewer(palette = \"Set1\") +   geom_smooth(method = \"loess\", span = 0.05) +   facet_wrap(~Pattern, scales = \"free\", ncol = 1) +   xlab(\"\") +   ylab(\"Pattern Score\") +   theme_classic() +   theme(     legend.position = \"none\",     title = element_text(size = 18),     axis.title.y = element_text(size = 18),     strip.text = element_text(size = 14),     axis.text.x = element_text(size = 13),     axis.text.y = element_text(size = 11)   ) +   scale_x_date(date_labels = \"%Y\", date_breaks = \"1 year\") +   ggtitle(\"PCP-NMF Scores over Time\") #> `geom_smooth()` using formula = 'y ~ x' nmf_sources %>%   mutate(Season = metR::season(Date)) %>%   group_by(Season, Pattern) %>%   summarise(     mean_score = mean(Score),     sd_score = sd(Score),     .groups = \"keep\"   ) %>%   ggplot(aes(Season, mean_score, color = Pattern)) +   scale_color_brewer(palette = \"Set1\") +   geom_point(size = 6) +   geom_errorbar(     aes(ymin = mean_score - sd_score, ymax = mean_score + sd_score),     width = 0.25, linewidth = 1.5   ) +   xlab(\"\") +   facet_wrap(~Pattern, scales = \"free_x\", ncol = 1) +   ylab(\"Factor Score\") +   theme_bw() +   theme(     title = element_text(size = 18),     legend.position = \"none\",     axis.title.y = element_text(size = 18),     axis.text.x.bottom = element_text(size = 13, color = \"black\"),     strip.text = element_text(size = 16),     axis.text.y.left = element_text(size = 12)   ) +   ggtitle(\"Mean (std dev) Pattern Scores by Season\") nmf_sources %>%   group_by(Pattern, DayofWeek) %>%   summarize(     mean_score = mean(Score),     sd_score = sd(Score),     .groups = \"keep\"   ) %>%   ggplot(aes(DayofWeek, mean_score, color = Pattern)) +   scale_color_brewer(palette = \"Set1\") +   geom_point(size = 6) +   geom_errorbar(     aes(ymin = mean_score - sd_score, ymax = mean_score + sd_score),     width = 0.25, linewidth = 1.5   ) +   xlab(\"\") +   facet_wrap(~Pattern, scales = \"free_x\", ncol = 1) +   ylab(\"Factor Score\") +   theme_bw() +   theme(     title = element_text(size = 18),     legend.position = \"none\",     axis.title.y = element_text(size = 18),     axis.text.x.bottom = element_text(size = 13, color = \"black\"),     strip.text = element_text(size = 16),     axis.text.y.left = element_text(size = 12)   ) +   ggtitle(\"Mean (std dev) Pattern Scores across Days of the Week\") nmf_sources %>%   mutate(     DayType = if_else(DayofWeek %in% c('Mon', 'Tue', 'Wed', 'Thu', 'Fri'), 'Weekday', 'Weekend'),     DayType = factor(DayType)   ) %>%   group_by(Pattern, DayType) %>%   summarize(     mean_score = mean(Score),     sd_score = sd(Score),     .groups = \"keep\"   ) %>%   ggplot(aes(DayType, mean_score, color = Pattern)) +   scale_color_brewer(palette = \"Set1\") +   geom_point(size = 6) +   geom_errorbar(     aes(ymin = mean_score - sd_score, ymax = mean_score + sd_score),     width = 0.25, linewidth = 1.5   ) +   xlab(\"\") +   facet_wrap(~Pattern, scales = \"free_x\", ncol = 1) +   ylab(\"Factor Score\") +   theme_bw() +   theme(     title = element_text(size = 18),     legend.position = \"none\",     axis.title.y = element_text(size = 18),     axis.text.x.bottom = element_text(size = 13, color = \"black\"),     strip.text = element_text(size = 16),     axis.text.y.left = element_text(size = 12)   ) +   ggtitle(\"Mean (std dev) Pattern Scores Weekend vs. Weekday\") ggcorr(   nmf_scores, method = c(\"pairwise.complete.obs\", \"pearson\"),   limits = FALSE, label = TRUE, label_size = 8,   hjust = 0.8, size = 8 )"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-applied.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Air pollution source apportionment with PCP","text":"paired PCP NMF source apportionment queens dataset 2015 - 2021. identified four patterns first identified pattern, accounting 31% commonly shared variance low-rank matrix, linked traffic road-related sources, characterized elements barium, calcium, lead, indicating emissions brake wear, tire wear, construction activities. second identified pattern, representing 21% variance, associated crustal dust, marked elements like aluminum, calcium, silicon, titanium, iron, suggesting resuspension natural materials soil rock. third pattern, comprising 14% variance, identified salt, including sodium chloride magnesium chloride. pattern peaks early spring, likely due accumulation road salt winter. fourth pattern, accounting 35% variance, represents mix regional/secondary sources traffic/tailpipe emissions, characterized sulfur, ammonium, nitrate, organic carbon, zinc. pattern lacks clear regional signal suggests contributions regional/secondary sources tailpipe emissions.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"simulating-data","dir":"Articles","previous_headings":"","what":"Simulating data","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"sim_data() function lets users generate simple mixtures models quick experimentation. Let’s use default parameters simulate noisy environmental mixture \\(D = L_0 + S_0 + Z_0\\) comprised \\(n = 100\\) observations \\(p = 10\\) chemicals, three underlying chemical exposure patterns (rank \\(r = 3\\)), extreme outlying exposure events along diagonal matrix, dense Gaussian noise corrupting measurements matrix: Let’s get sense matrices look like. Remember real world analyses, observe \\(D\\). matrices \\(L_0\\), \\(S_0\\), \\(Z_0\\) ground truth, coming unobserved data generating mechanism:     matrix_rank() function estimates rank given matrix counting number nonzero singular values governing matrix (help thresh parameter determining “practically zero”): can see L_0 3 underlying patterns. obscured observed, full-rank mixture matrix D, since S_0 Z_0 components corrupting underlying structure provided L_0. Let’s simulate chemicals (columns) data subject limit detection (LOD) sim_lod() function. simulate bottom 10th percentile column LOD, examine LOD column: Next, mixtures data often incomplete practice, let’s simulate random 5% values missing NA sim_na() function. missing values place, can finish simulating LOD mixture imputing values simulated < LOD \\(LOD / \\sqrt{2}\\), common imputation scheme measurements < LOD:  D_tilde matrix represents observed, messy mixtures model, suffering incomplete NA observations chemical-specific LOD.","code":"data <- sim_data() D <- data$D L_0 <- data$L S_0 <- data$S Z_0 <- data$Z plot_matrix(D) plot_matrix(L_0) plot_matrix(S_0) plot_matrix(Z_0) matrix_rank(L_0) #> [1] 3 matrix_rank(D) #> [1] 10 lod_info <- sim_lod(D, q = 0.1) D_lod <- lod_info$D_tilde lod <- lod_info$lod lod #>  [1] 0.2573431 0.5325583 0.2053927 0.2329695 0.1620019 0.3801870 0.6461348 #>  [8] 0.1499115 0.5306228 0.6183821 corrupted_data <- sim_na(D_lod, perc = 0.05) D_tilde <- corrupted_data$D_tilde lod_root2 <- matrix(   lod / sqrt(2),   nrow = nrow(D_tilde),   ncol = ncol(D_tilde), byrow = TRUE ) D_tilde[which(lod_info$tilde_mask == 1)] <- lod_root2[which(lod_info$tilde_mask == 1)] plot_matrix(D_tilde)"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model selection","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"two PCP algorithms shipped pcpr: convex root_pcp() [Zhang et al. (2021)] non-convex rrmc() [Cherapanamjeri et al. (2017)]. figure model best data, let’s inspect singular values observed mixture using sing() method (sing() accept missing values, use impute_matrix() impute NA values D_tilde respective column means):  rrmc() best suited data characterized slowly decaying singular values, indicative complex underlying patterns relatively large degree noise. EH data can described way. root_pcp() best data characterized rapidly decaying singular values, indicative well-defined latent patterns. simple example like , PCP models perfectly suitable. use rrmc(), model environmental health researchers likely employ frequently.","code":"D_imputed <- impute_matrix(D_tilde, apply(D_tilde, 2, mean, na.rm = TRUE)) singular_values <- sing(D_imputed) plot(singular_values, type = \"b\")"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"grid-search-for-parameter-tuning","dir":"Articles","previous_headings":"","what":"Grid search for parameter tuning","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"estimate low-rank sparse matrices, rrmc() needs given maximum rank r regularization parameter eta. determine optimal values r eta, conduct brief grid search using grid_search_cv() function. grid search , examine models ranks 1 5 values eta near default, calculated get_pcp_defaults(). rrmc() approach PCP uses iterative rank-based procedure recover L S, meaning first constructs rank 1 model iteratively builds specified rank r solution. , grid search, passed etas grid argument search sent \\(r = 5\\) constant parameter common models search. Since length(etas) = 6 \\(r = 5\\), searched 30 different PCP models. num_runs argument determines many (random) tests performed unique model setting. default, num_runs = 100, grid search tuned r eta measuring performance 300 different PCP models. passed simulated lod vector another constant grid search, equipping rrmc() run LOD information. Inspecting summary_stats table output grid search provides mean-aggregated statistics 30 distinct parameter settings tested. grid search correctly identified rank 3 solution best (lowest relative error rate). corresponding eta = 0.224.","code":"eta_0 <- get_pcp_defaults(D_tilde)$eta etas <- data.frame(\"eta\" = sort(c(0.1 * eta_0, eta_0 * seq(1, 10, 2)))) # could wrap this in a call to progressr::with_progress({ gs <- ... }) gs <- grid_search_cv(   D_tilde,   pcp_fn = rrmc,   grid = etas, r = 5, LOD = lod,   parallel_strategy = \"multisession\",   num_workers = 16,   verbose = FALSE ) r_star <- gs$summary_stats$r[1] eta_star <- round(gs$summary_stats$eta[1], 3) gs$summary_stats #> # A tibble: 30 × 7 #>      eta     r rel_err L_rank S_sparsity iterations run_error_perc #>    <dbl> <int>   <dbl>  <dbl>      <dbl>      <dbl> <chr>          #>  1 0.224     3   0.145   3         0.968        NaN 0%             #>  2 0.313     3   0.150   3         0.984        NaN 0%             #>  3 0.224     4   0.167   4         0.967        NaN 0%             #>  4 0.134     5   0.168   2.21      0.199        NaN 0%             #>  5 0.134     3   0.168   2.21      0.199        NaN 0%             #>  6 0.134     4   0.168   2.21      0.199        NaN 0%             #>  7 0.402     3   0.169   3         0.993        NaN 0%             #>  8 0.134     2   0.173   2         0.342        NaN 0%             #>  9 0.224     2   0.174   2         0.992        NaN 0%             #> 10 0.402     2   0.182   2         1.00         NaN 0%             #> # ℹ 20 more rows"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"running-pcp","dir":"Articles","previous_headings":"","what":"Running PCP","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"Now can run PCP model: can inspect evolution objective function course PCP’s optimization:  output L matrix:  Let’s briefly inspect PCP’s estimate sparse matrix S, fix values “practically” zero using hard_threshold() function. histogram shows majority entries S -0.4 0.4, call values “practically” zero, rest true outlying exposure events. can calculate sparsity S sparsity():","code":"pcp_model <- rrmc(D_tilde, r = r_star, eta = eta_star, LOD = lod) plot(pcp_model$objective, type = \"l\") plot_matrix(pcp_model$L) matrix_rank(pcp_model$L) #> [1] 3 hist(pcp_model$S) pcp_model$S <- hard_threshold(pcp_model$S, thresh = 0.4) plot_matrix(pcp_model$S) sparsity(pcp_model$S) #> [1] 0.989"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"benchmarking-with-pca","dir":"Articles","previous_headings":"","what":"Benchmarking with PCA","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"evaluating PCP model, let’s see well traditional method Principal Component Analysis (PCA) can recover L_0, provide benchmark comparison. proj_rank_r() function (project matrix rank r) approximates input matrix low-rank using rank-r truncated SVD, way PCA approximates low-rank matrix. Normally, researcher need determine r subjectively. give PCA advantage sharing PCP’s discovery grid search solution rank 3:","code":"L_pca <- proj_rank_r(D_imputed, r = r_star)"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"evaluating-pcp-against-the-ground-truth","dir":"Articles","previous_headings":"","what":"Evaluating PCP against the ground truth","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"Finally, let’s see recovering L_0 S_0. examine relative error model’s estimates simulated ground truth matrices. use Frobenius norm calculate relative errors matrices: PCP outperformed PCA quite bit! PCP’s relative recovery error L_0 matrix stood 5.85%, compared observed relative error 14.4% PCA’s relative error 8.1%. PCP’s sparse matrix estimate ground truth S_0 23.21%.","code":"data.frame(   \"Obs_rel_err\" = norm(L_0 - D_imputed, \"F\") / norm(L_0, \"F\"),   \"PCA_L_rel_err\" = norm(L_0 - L_pca, \"F\") / norm(L_0, \"F\"),   \"PCP_L_rel_err\" = norm(L_0 - pcp_model$L, \"F\") / norm(L_0, \"F\"),   \"PCP_S_rel_err\" = norm(S_0 - pcp_model$S, \"F\") / norm(S_0, \"F\"),   \"PCP_L_rank\" = matrix_rank(pcp_model$L),   \"PCP_S_sparsity\" = sparsity(pcp_model$S) ) #>   Obs_rel_err PCA_L_rel_err PCP_L_rel_err PCP_S_rel_err PCP_L_rank #> 1   0.1440249    0.08096932    0.05847706      0.232115          3 #>   PCP_S_sparsity #> 1          0.989"},{"path":"https://columbia-prime.github.io/pcpr/articles/pcp-quickstart.html","id":"after-pcp","dir":"Articles","previous_headings":"","what":"After PCP","title":"Quickstart: applying PCP to a simulated environmental mixture","text":"can now pair estimated L matrix matrix factorization method choice (e.g. PCA, factor analysis, non-negative matrix factorization) extract latent chemical exposure patterns. patterns, along isolated outlying exposure events S, can analyzed outcomes interest downstream epidemiological analyses.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"pcp-modeling-overview","dir":"Articles","previous_headings":"","what":"PCP modeling overview","title":"Theory crash course","text":"PCP algorithms model observed exposure matrix \\(D\\) sum three underlying ground-truth matrices:  low-rank matrix \\(L_0\\) encoding consistent patterns exposure, sparse matrix \\(S_0\\) isolating unique outlying exposure events (explained consistent exposure patterns), dense noise \\(Z_0\\). matrices dimension \\(n \\times p\\), \\(n\\) number observations (e.g. study participants measurement dates) \\(p\\) number exposures (e.g. chemical /non-chemical stressors). Beyond mixtures model, main assumption made PCP \\(Z_0 \\sim N(\\mu, \\sigma^2)\\) consists ..d. Gaussian noise corrupting entry overall exposure matrix \\(D\\). models pcpr seek decompose observed data matrix \\(D\\) estimated low-rank sparse components \\(L\\) \\(S\\) use downstream environmental health analyses.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"the-low-rank-matrix","dir":"Articles","previous_headings":"","what":"The low-rank matrix","title":"Theory crash course","text":"estimated low-rank matrix \\(L\\) provides information consistent exposure patterns, satisfying: \\[r = \\text{rank}(L) \\ll \\min(n, p).\\] rank \\(r\\) matrix number linearly independent columns rows matrix, plays important role defining mathematical structure data. Intuitively, rank directly corresponds (relatively ) number underlying patterns governing mixture. , “patterns” can refer specific sources, profiles behaviors leading exposure, depending application. Contrary closely related dimension reduction tools principal component analysis (PCA), PCP infers rank \\(r\\) observed data. pcpr, done directly optimization convex PCP, via grid search non-convex PCP. , rather require researcher choose number estimated patterns use subsequent health models, PCP allows observed data “speak ”, thereby removing potential points subjectivity model design. Notice \\(L \\\\mathbb{R}^{n \\times p}\\), meaning still defined terms original \\(n\\)-many observations \\(p\\)-many environmental variables. Put differently, \\(L\\) can taken robust approximation true environmental mixture matrix, unperturbed outliers (captured \\(S\\)) noise (handled PCP’s noise term). way, latent exposure patterns encoded \\(L\\) rather directly estimated. explicitly obtain exposure patterns \\(L\\), PCP may paired various matrix factorization methods (e.g., PCA, factor analysis, non-negative matrix factorization) yield chemical loadings individual scores use downstream health models. flexibility allows \\(L\\) adapt mixture-specific assumptions. example, assumption orthogonal (.e., independent) patterns strong, instead pairing \\(L\\) PCA, appropriate method factor analysis can used. Alternatively, depending sample size study design, \\(L\\) may also directly incorporated regression models.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"the-sparse-matrix","dir":"Articles","previous_headings":"","what":"The sparse matrix","title":"Theory crash course","text":"estimated sparse matrix \\(S\\) captures unusually high low outlying exposure events, unexplained identified patterns \\(L\\). entries \\(S\\) 0, non-zero entries identifying extreme exposure activity. number, location (.e., support), value non-zero entries \\(S\\) need priori defined; PCP isolates optimization. separating retaining sparse exposure events, PCP boasts enormous advantage current dimension reduction techniques. Despite common phenomena mixtures data, sparse outliers typically removed exposure matrix prior analysis. PCA conventional dimension reduction approaches unable disentangle unique events overall patterns exposure: included, even low fractions outliers can deviate patterns identified traditional methods away true distribution data, yielding inaccurate pattern estimations high false positive rates detected outliers. decomposing mixture low-rank sparse components \\(L\\) \\(S\\), PCP avoids pitfalls.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"extensions-for-environmental-health-data","dir":"Articles","previous_headings":"","what":"Extensions for environmental health data","title":"Theory crash course","text":"functions pcpr outfitted three environmental health (EH)-specific extensions, making pcpr particularly powerful EH research: Missing value functionality: PCP able recover NA values observed mixture matrix, often outperforming traditional imputation techniques. Leveraging potential limit detection (LOD) information: equipped LOD information, PCP treats estimations values known LOD equally valid approximations fall 0 LOD. PCP LOD data often outperforms PCA imputed \\(\\frac{LOD}{\\sqrt{2}}\\). Non-negativity constraint estimated L matrix: desired, PCP can enforce values estimated low-rank matrix L \\(\\geq 0\\), better modeling real world mixtures data.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"missing-value-functionality","dir":"Articles","previous_headings":"Extensions for environmental health data","what":"Missing value functionality","title":"Theory crash course","text":"PCP assumes data generating mechanisms govern missing observed entries \\(D\\). PCP primarily seeks accurate estimation patterns rather individual observations, assumption reasonable, edge cases may always justified. Missing values \\(D\\) therefore reconstructed recovered low-rank \\(L\\) matrix according underlying patterns \\(L\\). three corollaries keep mind regarding quality recovered missing observations: Recovery missing entries \\(D\\) relies accurate estimation \\(L\\); fewer observations \\(D\\), harder accurately reconstruct \\(L\\) (therefore estimation unobserved observed measurements \\(L\\) degrades); Greater proportions missingness \\(D\\) artifically drive sparsity estimated \\(S\\) matrix. possible recover sparse event \\(S\\) corresponding entry \\(D\\) unobserved. definition, sparse events \\(S\\) explained consistent patterns \\(L\\). Practically, 20% entries \\(D\\) missing, least 20% entries \\(S\\) 0.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"leveraging-potential-limit-of-detection-lod-information","dir":"Articles","previous_headings":"Extensions for environmental health data","what":"Leveraging potential limit of detection (LOD) information","title":"Theory crash course","text":"equipped \\(LOD\\) information, PCP treats estimations values known \\(LOD\\) equally valid approximations fall \\(0\\) \\(LOD\\). course optimization, observations LOD pushed known range \\([0, LOD]\\) using penalties : \\(< LOD\\) estimate \\(< 0\\), stringently penalized, since measured observations negative. hand, \\(< LOD\\) estimate \\(> LOD\\), also heavily penalized: less \\(< 0\\), observations known \\(LOD\\), prior information observations must \\(LOD\\). Observations known \\(LOD\\) penalized usual, using Frobenius norm objective function. Gibson et al. (2022) demonstrate experimental settings 50% data corrupted \\(LOD\\), PCP \\(LOD\\) extension boasts superior accuracy recovered \\(L\\) models compared PCA coupled \\(\\frac{LOD}{\\sqrt{2}}\\) imputation. PCP even outperforms PCA low-noise scenarios much 75% data corrupted \\(LOD\\). situations PCA bettered PCP pathological cases \\(D\\) characterized extreme noise huge proportions (.e., 75%) observations falling \\(LOD\\).","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"non-negativity-constraint-on-the-estimated-l-matrix","dir":"Articles","previous_headings":"Extensions for environmental health data","what":"Non-negativity constraint on the estimated L matrix","title":"Theory crash course","text":"enhance interpretability PCP-rendered solutions, optional non-negativity constraint can imposed \\(L\\) matrix ensure estimated values within \\(\\geq 0\\). prevents researchers deal negative observation values questions surrounding meaning utility. Non-negative \\(L\\) models also allow seamless use methods non-negative matrix factorization extract non-negative patterns. Currently, non-negativity constraint supported convex PCP function root_pcp(), incorporated ADMM splitting technique via introduction additional optimization variable corresponding constraint. Future work extend constraint non-convex PCP method rrmc().","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"convex-vs--non-convex-pcp","dir":"Articles","previous_headings":"","what":"Convex vs. non-convex PCP","title":"Theory crash course","text":"many flavors PCP undergoing active study current literature, provide two distinct models pcpr: convex model root_pcp() non-convex model rrmc(). table offers quick glance relative differences: Convex PCP via root_pcp() best data characterized rapidly decaying singular values, indicative well-defined latent patterns. Non-convex PCP rrmc() best suited data characterized slowly decaying singular values, indicative complex underlying patterns relatively large degree noise. EH data can described way, expect EH researchers utilize rrmc() analyses, however cases convexity root_pcp() may preferable.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"convex-pcp","dir":"Articles","previous_headings":"Convex vs. non-convex PCP","what":"Convex PCP","title":"Theory crash course","text":"Convex PCP formulations possess number particularly attractive properties, foremost convexity, meaning every local optimum global optimum, single best solution exists. Convex approaches PCP also virtue rank \\(r\\) recovered \\(L\\) matrix determined optimization, without researcher input. Unfortunately, benefits come cost: convex PCP programs expensive run large datasets, suffering poor convergence rates. Moreover, convex PCP approaches best suited instances target low-rank matrix \\(L_0\\) can accurately modelled low-rank (.e. \\(L_0\\) governed well-defined patterns). often case image video data (characterized rapidly decaying singular values), common EH data. EH data typically approximately low-rank (characterized complex patterns slowly decaying singular values). convex model available pcpr root_pcp(). comprehensive technical understanding, refer readers Zhang et al. (2021) introducing algorithm. root_pcp() optimizes following objective function: \\[\\min_{L, S} ||L||_* + \\lambda ||S||_1 + \\mu ||L + S - D||_F\\] first term nuclear norm L matrix, incentivizing \\(L\\) low-rank. second term \\(\\ell_1\\) norm S matrix, encouraging S sparse. third term Frobenius norm applied model’s noise, ensuring estimated low-rank sparse models \\(L\\) \\(S\\) together high fidelity observed data \\(D\\). objective smooth differentiable, however convex separable. , optimized using Alternating Direction Method Multipliers (ADMM) algorithm Boyd et al. (2011), Gao et al. (2020).","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"non-convex-pcp","dir":"Articles","previous_headings":"Convex vs. non-convex PCP","what":"Non-convex PCP","title":"Theory crash course","text":"alleviate high computational complexity convex methods, non-convex PCP frameworks developed. drastically improve upon convergence rates convex counterparts. Better still, non-convex PCP methods flexibly accommodate data lacking well-defined low-rank structure, outset better suited handling EH data. Non-convex formulations provide flexibility allowing user interrogate data different ranks. drawback non-convex algorithms can longer determine rank best describing data autonomously, instead requiring researcher subjectively specify rank \\(r\\) PCA. One glaring trade-offs made non-convex methods improved run-time flexibility weaker theoretical promises; specifically, non-convex PCP runs risk finding spurious local optima, rather global optimum guaranteed convex siblings. said , theory developed guaranteeing equivalent performance non-convex implementations closely related convex formulations certain conditions. advancements provide strong motivation non-convex frameworks despite weaker theoretical promises. non-convex model available pcpr rrmc(). refer readers Cherapanamjeri et al. (2017) depth look mathematical details. rrmc() implicitly optimizes following objective function: \\[\\min_{L, S} I_{rank(L) \\leq r} + \\eta ||S||_0 + ||L + S - D||_F^2\\] first term indicator function checking \\(L\\) matrix strictly rank \\(r\\) less, implemented using rank \\(r\\) projection operator proj_rank_r(). second term \\(\\ell_0\\) norm applied \\(S\\) matrix encourage sparsity, implemented help adaptive hard-thresholding operator hard_threshold(). third term squared Frobenius norm applied model’s noise. rrmc() uses incremental rank-based strategy order estimate \\(L\\) \\(S\\): First, rank-\\(1\\) model \\((L^{(1)}, S^{(1)})\\) estimated. rank-\\(1\\) model used initialization point construct rank-\\(2\\) model \\((L^{(2)}, S^{(2)})\\), , desired rank-r model \\((L^{(r)}, S^{(r)})\\) recovered. models ranks \\(1\\) \\(r\\) returned rrmc() way.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"intuition-behind-lambda-mu-and-eta","dir":"Articles","previous_headings":"PCP parameters","what":"Intuition behind lambda, mu, and eta","title":"Theory crash course","text":"Recall root_pcp()’s objective function given : \\[\\min_{L, S} ||L||_* + \\lambda ||S||_1 + \\mu ||L + S - D||_F\\] \\(\\lambda\\) (lambda) controls sparsity root_pcp()’s output \\(S\\) matrix; larger values \\(\\lambda\\) penalize non-zero entries \\(S\\) stringently, driving recovery sparser \\(S\\) matrices. Therefore, priori expect outlying events model, might expect grid search recover relatively larger \\(\\lambda\\) values, vice-versa. \\(\\mu\\) (mu) adjusts root_pcp()’s sensitivity noise; larger values \\(\\mu\\) penalize errors predicted model observed data (.e. noise), severely. Environmental data subject higher noise levels therefore require root_pcp() model equipped smaller mu values (since higher noise means greater discrepancy observed mixture true underlying low-rank sparse model). virtually noise-free settings (e.g. simulations), larger values \\(\\mu\\) appropriate. rrmc()’s objective function given : \\[\\min_{L, S} I_{rank(L) \\leq r} + \\eta ||S||_0 + ||L + S - D||_F^2\\] \\(\\eta\\) (eta) controls sparsity rrmc()’s output \\(S\\) matrix, just \\(\\lambda\\) root_pcp(). parameters scaling noise term, \\(\\eta\\) can thought ratio root_pcp()’s \\(\\lambda\\) \\(\\mu\\): Larger values \\(\\eta\\) place greater emphasis penalizing non-zero entries \\(S\\) penalizing errors predicted observed data (dense noise \\(Z\\)).","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"theoretically-optimal-parameters","dir":"Articles","previous_headings":"PCP parameters","what":"Theoretically optimal parameters","title":"Theory crash course","text":"get_pcp_defaults() function calculates “default” PCP parameter settings \\(\\lambda\\), \\(\\mu\\) \\(\\eta\\) given data matrix \\(D\\). “default” values \\(\\lambda\\) \\(\\mu\\) offer theoretical guarantees optimal estimation performance. Candès et al. (2011) obtained guarantee \\(\\lambda\\), Zhang et al. (2021) obtained result \\(\\mu\\). yet proven whether \\(\\eta\\) enjoys similar properties. theoretically optimal \\(\\lambda_*\\) given : \\[\\lambda_* = 1 / \\sqrt{\\max(n, p)},\\] \\(n\\) \\(p\\) dimensions input matrix \\(D_{n \\times p}\\). theoretically optimal \\(\\mu_*\\) given : \\[\\mu_* = \\sqrt{\\frac{\\min(n, p)}{2}}.\\] “default” value \\(\\eta\\) simply \\(\\eta = \\frac{\\lambda_*}{\\mu_*}\\).","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"empirically-optimal-parameters","dir":"Articles","previous_headings":"PCP parameters","what":"Empirically optimal parameters","title":"Theory crash course","text":"Mixtures data rarely well-behaved practice, however. Instead, common find different empirically optimal parameter values tuning parameters grid search. Therefore, recommended use get_pcp_defaults() primarily help define reasonable initial parameter search space pass grid_search_cv().","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"cross-validation-procedure","dir":"Articles","previous_headings":"Tuning parameters with grid_search_cv()","what":"Cross-validation procedure","title":"Theory crash course","text":"grid_search_cv() conducts Monte Carlo style cross-validated grid search PCP parameters given data matrix \\(D\\), PCP function pcp_fn, grid parameter settings search grid. run time grid search can sped using bespoke parallelization settings. hyperparameter setting cross-validated : Randomly corrupting \\(\\xi\\) percent entries \\(D\\) missing (.e. NA values), yielding \\(P_\\Omega(D)\\). Done using sim_na() function. Running given PCP function pcp_fn \\(P_\\Omega(D)\\), yielding estimates \\(L\\) \\(S\\). Recording relative recovery error \\(L\\) compared input data matrix \\(D\\) values imputed missing corruption step (step 1 ). Formally, relative error calculated : \\[RelativeError(L | D) := \\frac{||P_{\\Omega^c}(D - L)||_F}{||P_{\\Omega^c}(D)||_F}\\] Re-running steps 1-3 total \\(K\\)-many runs (“run” unique random seed 1 \\(K\\) associated ). Performance statistics can calculated “run”, summarized across runs using mean-aggregated statistics. grid_search_cv() function, \\(\\xi\\) referred perc_test (percent test), \\(K\\) known num_runs (number runs).","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"best-practices-for-xi-and-k","dir":"Articles","previous_headings":"Tuning parameters with grid_search_cv()","what":"Best practices for \\(\\xi\\) and \\(K\\)","title":"Theory crash course","text":"Experimentally, grid search procedure retrieves best performing PCP parameter settings \\(\\xi\\) relatively low, e.g. \\(\\xi = 0.05\\), 5%, \\(K\\) relatively high, e.g. \\(K = 100\\). : larger \\(\\xi\\) , test set turns matrix completion problem, rather desired matrix decomposition problem. better resemble actual problem PCP faced come inference time, \\(\\xi\\) therefore kept relatively low. Choosing reasonable value \\(K\\) dependent need keep \\(\\xi\\) relatively low. Ideally, large enough \\(K\\) used many () entries \\(D\\) likely eventually tested. Note since test set entries chosen randomly runs \\(1\\) \\(K\\), pathologically worst case scenario, exact test set drawn time. best case scenario, different test set obtained run, providing balanced coverage \\(D\\). Viewed another way, smaller \\(K\\) , results susceptible overfitting relatively selected test sets.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"interpretaion-of-results","dir":"Articles","previous_headings":"Tuning parameters with grid_search_cv()","what":"Interpretaion of results","title":"Theory crash course","text":"grid search conducted, optimal hyperparameters can chosen examining output statistics summary_stats. suggestions interpret summary_stats table: Generally speaking, first thing user want inspect rel_err statistic, capturing relative discrepancy recovered test sets original, observed (yet possibly noisy) values. Lower rel_err means PCP model better able recover held-test set. , general, best parameter settings lowest rel_err. said , important remember statistic taken grain salt: practice researcher access ground truth \\(L\\) matrix, rel_err measurement forced rely comparison noisy observed data matrix \\(D\\) estimated low-rank model \\(L\\). rel_err metric “apples oranges” relative error. data priori expected subject high degree noise, may actually better discard parameter settings suspiciously low rel_errs (case solution may hallucinating inaccurate low-rank structure observed noise). grid searches using root_pcp() PCP model, parameters fail converge can discarded. Generally, fewer root_pcp() iterations (num_iter) taken reach convergence portend reliable / stable solution. rare cases, user may need increase root_pcp()’s max_iter argument reach convergence. rrmc() report convergence metadata, optimization scheme runs fixed number iterations. Parameter settings unreasonable sparsity rank measurements can also discarded. , “unreasonable” means reported metrics flagrantly contradict prior assumptions, knowledge, work. instance, air pollution datasets contain number extreme exposure events, PCP solutions returning sparse \\(S\\) models 100% sparsity obviously regularized heavily. Note reported sparsity rank measurements estimates heavily dependent thresh set sparsity() & matrix_rank() functions. E.g. actual average matrix rank much higher lower threshold better takes account relative scale singular values used. Likewise sparsity estimations. Also, recall given value \\(\\xi\\) artifically sets sparsity floor, since missing entries test set recovered \\(S\\) matrix. E.g. \\(\\xi = 0.05\\), parameter setting estimated sparsity lower 5%.","code":""},{"path":"https://columbia-prime.github.io/pcpr/articles/theory-crash-course.html","id":"coded-example-analyses","dir":"Articles","previous_headings":"","what":"Coded example analyses","title":"Theory crash course","text":"see apply pcpr, recommend reading: vignette(\"pcp-quickstart\"): applying PCP simulated environmental mixture vignette(\"pcp-applied\"): employing PCP source apportionment real-world PM2.5 data using queens dataset","code":""},{"path":"https://columbia-prime.github.io/pcpr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lawrence G. Chillrud. Author, maintainer, copyright holder. Jaime Benavides. Author. Elizabeth . Gibson. Author. Junhui Zhang. Author. Jingkai Yan. Author. John N. Wright. Author. Jeff Goldsmith. Author. Marianthi-Anna Kioumourtzoglou. Author. . Funder.           00hj8s172","code":""},{"path":"https://columbia-prime.github.io/pcpr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chillrud L, Benavides J, Gibson E, Zhang J, Yan J, Wright J, Goldsmith J, Kioumourtzoglou M (2025). pcpr: Principal Component Pursuit Environmental Epidemiology. R package version 1.0.0, https://github.com/Columbia-PRIME/pcpr, https://columbia-prime.github.io/pcpr/.","code":"@Manual{,   title = {pcpr: Principal Component Pursuit for Environmental Epidemiology},   author = {Lawrence G. Chillrud and Jaime Benavides and Elizabeth A. Gibson and Junhui Zhang and Jingkai Yan and John N. Wright and Jeff Goldsmith and Marianthi-Anna Kioumourtzoglou},   year = {2025},   note = {R package version 1.0.0,     https://github.com/Columbia-PRIME/pcpr},   url = {https://columbia-prime.github.io/pcpr/}, }"},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"pcpr-","dir":"","previous_headings":"","what":"Principal Component Pursuit for Environmental Epidemiology","title":"Principal Component Pursuit for Environmental Epidemiology","text":"R package pcpr implements Principal Component Pursuit (PCP), robust dimensionality reduction technique, pattern recognition tailored environmental health data. statistical methodology computational details provided Gibson et al. (2022).","code":""},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Principal Component Pursuit for Environmental Epidemiology","text":"can install development version pcpr GitHub : pcpr can loaded attached current R session usual ","code":"# install.packages(\"pak\") pak::pak(\"Columbia-PRIME/pcpr\") library(pcpr)"},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Principal Component Pursuit for Environmental Epidemiology","text":"Extensive documentation available pkgdown website offline within R. can see pcpr reference manual R : number vignettes available within R. can browsed using: recommend reading vignettes following order: Theory crash course, directly R: vignette(\"theory-crash-course\") Quickstart, directly R: vignette(\"pcp-quickstart\") Air pollution source apportionment PCP, directly R: vignette(\"pcp-applied\") bug report quesion ask? Open issue GitHub.","code":"help(\"pcpr\") browseVignettes(\"pcpr\")"},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"modeling-overview","dir":"","previous_headings":"","what":"Modeling overview","title":"Principal Component Pursuit for Environmental Epidemiology","text":"PCP algorithms model observed exposure matrix \\(D\\) sum three underlying ground-truth matrices: PCP mixtures model visualized low-rank matrix \\(L_0\\) encoding consistent patterns exposure, sparse matrix \\(S_0\\) isolating unique outlying exposure events (explained consistent exposure patterns), dense noise \\(Z_0\\). models pcpr seek decompose observed data matrix D estimated low-rank sparse components L S use downstream environmental health analyses. functions pcpr outfitted three environmental health (EH)-specific extensions making pcpr particularly powerful EH research: Missing value functionality Leveraging potential limit detection (LOD) information Non-negativity constraint estimated L matrix","code":""},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"pcp-in-environmental-health-studies","dir":"","previous_headings":"","what":"PCP in environmental health studies","title":"Principal Component Pursuit for Environmental Epidemiology","text":"methods pcpr already applied many environmental health studies. Several listed : Tao et al. (2023) apply PCP investigate association source-specific fine particulate matter myocardial infarction hospitalizations NYC. Wu et al. (2024) employ PCP exposome profiling environmental pollutants seminal plasma, uncovering novel associations semen parameters. Benavides et al. (2024) use PCP develop Community Severity Index NYC, measuring barrier effect road infrastructure traffic cities.","code":""},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Principal Component Pursuit for Environmental Epidemiology","text":"Please cite use pcpr : Chillrud L, Benavides J, Gibson E, Zhang J, Yan J, Wright J, Goldsmith J, Kioumourtzoglou M (2025). pcpr: Principal Component Pursuit Environmental Epidemiology. R package version 1.0.0, https://columbia-prime.github.io/pcpr/, https://github.com/Columbia-PRIME/pcpr. Please also cite Gibson et al. (2022). work supported NIEHS PRIME R01 ES028805. Special thanks Sophie Calhoun designing pcpr’s logo!","code":"@Manual{,   title = {pcpr: Principal Component Pursuit for Environmental Epidemiology},   author = {Lawrence G. Chillrud and Jaime Benavides and Elizabeth A. Gibson and Junhui Zhang and Jingkai Yan and John N. Wright and Jeff Goldsmith and Marianthi-Anna Kioumourtzoglou},   year = {2025},   note = {R package version 1.0.0, https://github.com/Columbia-PRIME/pcpr},   url = {https://columbia-prime.github.io/pcpr/}, }"},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Principal Component Pursuit for Environmental Epidemiology","text":"","code":"# Simulate an environmental mixture data <- sim_data(   n = 100, p = 10, r = 3,   sparse_nonzero_idxs = seq(1, 1000, 101),   sigma = 0.05 ) D <- data$D # Observed matrix L_0 <- data$L # Ground truth low-rank matrix S_0 <- data$S # Ground truth sparse matrix Z_0 <- data$Z # Ground truth noise matrix  # Simulate a limit of detection for each chemical in mixture lod_info <- sim_lod(D, q = 0.1) lod <- lod_info$lod  # Simulate missing observations corrupted_data <- sim_na(D, perc = 0.05) D_tilde <- corrupted_data$D_tilde  # Run grid search to obtain optimal r, eta parameters # (Not shown here to save space, see vignette(\"pcp-quickstart\") # for full example which obtains r = 3, eta = 0.224) r_star <- 3 eta_star <- 0.224  # Run non-convex PCP to estimate L, S from D_tilde pcp_model <- rrmc(D_tilde, r = r_star, eta = eta_star, LOD = lod)  # Benchmark with PCA's attempt at recovering L D_imputed <- impute_matrix(D_tilde, apply(D_tilde, 2, mean, na.rm = TRUE)) L_pca <- proj_rank_r(D_imputed, r = r_star)  # Evaluate PCP ground truth data.frame(   \"Obs_rel_err\" = norm(L_0 - D_imputed, \"F\") / norm(L_0, \"F\"),   \"PCA_L_rel_err\" = norm(L_0 - L_pca, \"F\") / norm(L_0, \"F\"),   \"PCP_L_rel_err\" = norm(L_0 - pcp_model$L, \"F\") / norm(L_0, \"F\"),   \"PCP_S_rel_err\" = norm(S_0 - pcp_model$S, \"F\") / norm(S_0, \"F\"),   \"PCP_L_rank\" = matrix_rank(pcp_model$L),   \"PCP_S_sparsity\" = sparsity(pcp_model$S) ) #>   Obs_rel_err PCA_L_rel_err PCP_L_rel_err PCP_S_rel_err PCP_L_rank #> 1   0.1496416    0.08674625    0.05215485     0.3600219          3 #>   PCP_S_sparsity #> 1          0.964"},{"path":"https://columbia-prime.github.io/pcpr/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Principal Component Pursuit for Environmental Epidemiology","text":"Gibson, Elizabeth ., Junhui Zhang, Jingkai Yan, Lawrence Chillrud, Jaime Benavides, Yanelli Nunez, Julie B. Herbstman, Jeff Goldsmith, John Wright, Marianthi-Anna Kioumourtzoglou. “Principal component pursuit pattern identification environmental mixtures.” Environmental Health Perspectives 130, . 11 (2022): 117008. [available ] Tao, Rachel H., Lawrence G. Chillrud, Yanelli Nunez, Sebastian T. Rowland, Amelia K. Boehme, Jingkai Yan, Jeff Goldsmith, John Wright, Marianthi-Anna Kioumourtzoglou. “Applying principal component pursuit investigate association source-specific fine particulate matter myocardial infarction hospitalizations New York City.” Environmental Epidemiology 7 (2), (2023). [available ] Wu, Haotian, Vrinda Kalia, Katherine E. Manz, Lawrence Chillrud, Nathalie Hoffmann Dishon, Gabriela L. Jackson, Christian K. Dye, Raoul Orvieto, Adva Aizer, Hagai Levine, Marianthi-Anna Kioumourtzoglou, Kurt D. Pennell, Andrea . Baccarelli, Ronit Machtinger. “Exposome Profiling Environmental Pollutants Seminal Plasma Novel Associations Semen Parameters.” Environmental Science & Technology, 58 (31), (2024): 13594-13604. [available ] Benavides, Jaime, Sabah Usmani, Vijay Kumar, Marianthi-Anna Kioumourtzoglou. “Development community severance index urban areas United States: case study New York City.” Environment International, 185, (2024): 108526. [available ]","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/eval_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate parameters — eval_params","title":"Evaluate parameters — eval_params","text":"Given documented parameter settings settings, test matrix test_mat, PCP solution pcp_model, binary mask test_mask, returns statistics pcp_model's performance settings test_mat. internal function needed grid_search_cv(). expected users require access function.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/eval_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate parameters — eval_params","text":"","code":"eval_params(settings, test_mat, pcp_model, test_mask)"},{"path":"https://columbia-prime.github.io/pcpr/reference/eval_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate parameters — eval_params","text":"settings Documented parameter settings associated given pcp_model. test_mat given test matrix test_mask observed (.e. missing). pcp_model output PCP algorithm, either rrmc() root_pcp(). test_mask binary mask indicating entries test_mat comprise test set.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/eval_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate parameters — eval_params","text":"data.frame object PCP's performance statistics.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"get_pcp_defaults() calculates \"default\" PCP parameter settings lambda, mu (used root_pcp()), eta (used rrmc()) given data matrix D. \"default\" values lambda mu offer theoretical guarantees optimal estimation performance. Candès et al. (2011) obtained guarantee lambda, Zhang et al. (2021) obtained result mu. yet proven whether eta enjoys similar properties. practice common find different optimal parameter values tuning parameters grid search. Therefore, recommended use defaults primarily help define reasonable initial parameter search space pass grid_search_cv().","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"","code":"get_pcp_defaults(D)"},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"D input data matrix.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"list containing: lambda: theoretically optimal lambda value used root_pcp(). mu: theoretically optimal mu value used root_pcp(). eta: default eta value used rrmc().","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"the-intuition-behind-pcp-parameters","dir":"Reference","previous_headings":"","what":"The intuition behind PCP parameters","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"root_pcp()'s objective function given : $$\\min_{L, S} ||L||_* + \\lambda ||S||_1 + \\mu ||L + S - D||_F$$ lambda controls sparsity root_pcp()'s output S matrix; larger values lambda penalize non-zero entries S stringently, driving recovery sparser S matrices. Therefore, priori expect outlying events model, might expect grid search recover relatively larger lambda values, vice-versa. mu adjusts root_pcp()'s sensitivity noise; larger values mu penalize errors predicted model observed data (.e. noise), severely. Environmental data subject higher noise levels therefore require root_pcp() model equipped smaller mu values (since higher noise means greater discrepancy observed mixture true underlying low-rank sparse model). virtually noise-free settings (e.g. simulations), larger values mu appropriate. rrmc()'s objective function given : $$\\min_{L, S} I_{rank(L) \\leq r} + \\eta ||S||_0 + ||L + S - D||_F^2$$ eta controls sparsity rrmc()'s output S matrix, just lambda root_pcp(). parameters scaling noise term, eta can thought ratio root_pcp()'s lambda mu: Larger values eta place greater emphasis penalizing non-zero entries S penalizing errors predicted observed data (dense noise Z).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"the-calculation-of-the-default-pcp-parameters","dir":"Reference","previous_headings":"","what":"The calculation of the \"default\" PCP parameters","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"lambda calculated \\(\\lambda = 1 / \\sqrt{\\max(n, p)},\\) \\(n\\) \\(p\\) dimensions input matrix \\(D_{n \\times p}\\) Candès et al. (2011). mu calculated \\(\\mu = \\sqrt{\\frac{\\min(n, p)}{2}},\\) \\(n\\) \\(p\\) [Zhang et al. (2021)]. eta simply \\(\\eta = \\frac{\\lambda}{\\mu}\\).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"Candès, Emmanuel J., Xiaodong Li, Yi Ma, John Wright. \"Robust principal component analysis?.\" Journal ACM (JACM) 58, . 3 (2011): 1-37. Zhang, Junhui, Jingkai Yan, John Wright. \"Square root principal component pursuit: tuning-free noisy robust matrix recovery.\" Advances Neural Information Processing Systems 34 (2021): 29464-29475. [available ]","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/get_pcp_defaults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve default PCP parameter settings for given matrix — get_pcp_defaults","text":"","code":"# Examine the queens PM2.5 data queens #> # A tibble: 2,443 × 27 #>    Date            Al   NH4      As     Ba       Br     Cd      Ca      Cl #>    <date>       <dbl> <dbl>   <dbl>  <dbl>    <dbl>  <dbl>   <dbl>   <dbl> #>  1 2001-04-04 NA      1.62  NA      NA     NA       NA     NA      NA      #>  2 2001-04-07  0      2.66   0       0.012  0.00488  0      0.0401  0.0079 #>  3 2001-04-13  0.0094 1.41   0.0016  0.024  0.00211  0.004  0.036   0      #>  4 2001-04-19  0.0104 1.22   0.001   0.006  0.00422  0      0.0543  0.003  #>  5 2001-04-25  0.0172 0.723  0.0024  0.015  0.00117  0      0.0398  0      #>  6 2001-05-01  0.0384 3.48   0.0017  0.041  0.00873  0.001  0.136   0      #>  7 2001-05-04  0.0964 6.22   0.0025  0.039  0.0111   0      0.137   0      #>  8 2001-05-07  0.004  0.233  0.001   0.016  0.00263  0      0.055   0.0054 #>  9 2001-05-10  0.0547 2.04   0.001   0.055  0.00521  0      0.121   0.001  #> 10 2001-05-13  0.0215 0.229  0       0.021  0.00122  0      0.0249  0      #> # ℹ 2,433 more rows #> # ℹ 18 more variables: Cr <dbl>, Cu <dbl>, EC <dbl>, Fe <dbl>, Pb <dbl>, #> #   Mg <dbl>, Mn <dbl>, Ni <dbl>, OC <dbl>, K <dbl>, Se <dbl>, Si <dbl>, #> #   Na <dbl>, S <dbl>, Ti <dbl>, NO3 <dbl>, V <dbl>, Zn <dbl> # Get rid of the Date column D <- as.matrix(queens[, 2:ncol(queens)]) # Get default PCP parameters default_params <- get_pcp_defaults(D) # Use default parameters to define parameter search space scaling_factors <- sort(c(10^seq(-2, 4, 1), 2 * 10^seq(-2, 4, 1))) etas_to_grid_search <- default_params$eta * scaling_factors etas_to_grid_search #>  [1] 5.611340e-05 1.122268e-04 5.611340e-04 1.122268e-03 5.611340e-03 #>  [6] 1.122268e-02 5.611340e-02 1.122268e-01 5.611340e-01 1.122268e+00 #> [11] 5.611340e+00 1.122268e+01 5.611340e+01 1.122268e+02"},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validated grid search for PCP models — grid_search_cv","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"grid_search_cv() conducts Monte Carlo style cross-validated grid search PCP parameters given data matrix D, PCP function pcp_fn, grid parameter settings search grid. run time grid search can sped using bespoke parallelization settings. call grid_search_cv() can wrapped call progressr::with_progress() progress bar updates. See sections details.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"","code":"grid_search_cv(   D,   pcp_fn,   grid,   ...,   parallel_strategy = \"sequential\",   num_workers = 1,   perc_test = 0.05,   num_runs = 100,   return_all_tests = FALSE,   verbose = TRUE )"},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"D input data matrix (can contain NA values). Note PCP converge much quickly D standardized way (e.g. scaling columns standard deviations, column-wise min-max normalization). pcp_fn PCP function use grid searching. Must either rrmc root_pcp (passed without soft brackets). grid data.frame dimension j k containing j-many unique settings k-many parameters try. NOTE: columns grid named required parameters function header pcp_fn. example, pcp_fn = root_pcp want search lambda mu, names(grid) must set c(\"lambda\", \"mu\"). instead want keep e.g. lambda fixed search mu, can either grid one column, mu, pass lambda constant via ..., can names(grid) set c(\"lambda\", \"mu\") lambda constant. logic applies pcp_fn = rrmc eta r. ... parameters required pcp_fn kept constant throughout grid search, parameters stored grid (e.g. LOD parameter). parameter passed ... already column grid, behavior ambiguous. parallel_strategy (Optional) parallelization strategy used conducting grid search (passed future::plan() function). Must one : \"sequential\", \"multisession\", \"multicore\" \"cluster\". default, parallel_strategy = \"sequential\", runs grid search serial num_workers argument ignored. option parallel_strategy = \"multisession\" parallelizes search via sockets separate R sessions. option parallel_strategy = \"multicore\" supported Windows machines, .Rmd files (must run .R script) parallelizes search much faster \"multisession\" since runs separate forked R processes. option parallel_strategy = \"cluster\" parallelizes using separate R sessions running typically one machines. Support parallel strategies added future release pcpr. recommended use parallel_strategy = \"multicore\" \"multisession\" possible. num_workers (Optional) integer specifying number workers use parallelizing grid search, passed future::plan(). default, num_workers = 1. possible, recommended use num_workers = parallel::detectCores(logical = F), computes number physical CPUs available machine (see parallel::detectCores()). num_workers ignored parallel_strategy = \"sequential\", must > 1 otherwise. perc_test (Optional) fraction entries D randomly corrupted NA missing values (test set). Can anthing range [0, 1). default, perc_test = 0.05. See Best practices section details. num_runs (Optional) number times test given parameter setting. default, num_runs = 100. See Best practices section details. return_all_tests (Optional) logical indicating like output calls made pcp_fn course grid search returned list format. set FALSE, statistics parameters tested returned. set TRUE every L, S matrix recovered grid search returned lists L_mats S_mats, every test set matrix returned list test_mats, original input matrix returned original_mat, parameters passed ... returned constant_params list. default, return_all_tests = FALSE, highly recommended. Setting return_all_tests = TRUE can consume massive amount memory depending size grid, input matrix D, value num_runs. verbose (Optional) logical indicating like verbose output displayed . default, verbose = TRUE. obtain progress bar updates, user must wrap grid_search_cv() call call progressr::with_progress(). progress bar depend value passed verbose.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"list containing: all_stats: data.frame containing statistics every run comprising grid search. statistics include parameter settings run, along run_num (used seed corruption step, step 1 grid search procedure), relative error run rel_err, rank recovered L matrix L_rank, sparsity recovered S matrix S_sparsity, number iterations PCP took reach convergence (root_pcp() ), error status run_error PCP run (NA error, otherwise character string). summary_stats: data.frame containing summary information all_stats. Summary made column-wise averaging results all_stats. metadata: character string containing metadata associated grid search instance. return_all_tests = TRUE following also returned part list: L_mats: list containing L matrices returned PCP throughout grid search. Therefore, length(L_mats) == nrow(all_stats). Row all_stats corresponds L_mats[[]]. S_mats: list containing S matrices returned PCP throughout grid search. Therefore, length(S_mats) == nrow(all_stats). Row all_stats corresponds S_mats[[]]. test_mats: list length(num_runs) containing corrupted test mats (masks) used throughout grid search. Note: all_stats$run[] corresponds test_mats[[]]. original_mat: original data matrix D. constant_params: copy constant parameters originally passed grid search (record keeping).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"the-monte-carlo-style-cross-validation-procedure","dir":"Reference","previous_headings":"","what":"The Monte Carlo style cross-validation procedure","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"hyperparameter setting cross-validated : Randomly corrupting perc_test percent entries D missing (.e. NA values), yielding D_tilde. Done via sim_na(). Running PCP function pcp_fn D_tilde, yielding estimates L S. Recording relative recovery error L compared input data matrix D values imputed missing corruption step (step 1 ). Mathematically, calculate: \\(||P_{\\Omega^c}(D - L)||_F / ||P_{\\Omega^c}(D)||_F\\), \\(P_{\\Omega^c}\\) selects entries .na(D_tilde) == TRUE. Repeating steps 1-3 total num_runs-many times, \"run\" unique random seed 1 num_runs associated . Performance statistics can calculated \"run\", summarized across runs average model performance statistics.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"best-practices-for-perc-test-and-num-runs","dir":"Reference","previous_headings":"","what":"Best practices for perc_test and num_runs","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"Experimentally, grid search procedure retrieves best performing PCP parameter settings perc_test relatively low, e.g. perc_test = 0.05, 5%, num_runs relatively high, e.g. num_runs = 100. larger perc_test , test set turns matrix completion problem, rather desired matrix decomposition problem. better resemble actual problem PCP faced come inference time, perc_test therefore kept relatively low. Choosing reasonable value num_runs dependent need keep perc_test relatively low. Ideally, large enough num_runs used many () entries D likely eventually tested. Note since test set entries chosen randomly runs 1 num_runs, pathologically worst case scenario, exact test set drawn time. best case scenario, different test set obtained run, providing balanced coverage D. Viewed another way, smaller num_runs , results susceptible overfitting relatively selected test sets.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"interpretaion-of-results","dir":"Reference","previous_headings":"","what":"Interpretaion of results","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"grid search conducted, optimal hyperparameters can chosen examining output statistics summary_stats. suggestions interpret summary_stats table: Generally speaking, first thing user want inspect rel_err statistic, capturing relative discrepancy recovered test sets original, observed (yet possibly noisy) values. Lower rel_err means PCP model better able recover held-test set. , general, best parameter settings lowest rel_err. said , important remember statistic taken grain salt: ground truth L matrix exists, rel_err measurement forced rely comparison noisy observed data matrix D estimated low-rank model L. rel_err metric \"apples oranges\" relative error. data priori expected subject high degree noise, may actually better discard parameter settings suspiciously low rel_errs (case solution may hallucinating inaccurate low-rank structure observed noise). grid searches using root_pcp() PCP model, parameters fail converge can discarded. Generally, fewer root_pcp() iterations (num_iter) taken reach convergence portend reliable / stable solution. rare cases, user may need increase root_pcp()'s max_iter argument reach convergence. rrmc() report convergence metadata, optimization scheme runs fixed number iterations. Parameter settings unreasonable sparsity rank measurements can also discarded. , \"unreasonable\" means reported metrics flagrantly contradict prior assumptions, knowledge, work. instance, air pollution datasets contain number extreme exposure events, PCP solutions returning sparse S models 100% sparsity obviously regularized heavily. Solutions lower sparsities preferred. Note reported sparsity rank measurements estimates heavily dependent thresh set sparsity() & matrix_rank() functions. E.g. actual average matrix rank much higher lower threshold better takes account relative scale singular values used. Likewise sparsity estimations. Also, recall given value perc_test artifically sets sparsity floor, since missing entries test set recovered S matrix. E.g. perc_test = 0.05, parameter setting estimated sparsity lower 5%.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/grid_search_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validated grid search for PCP models — grid_search_cv","text":"","code":"#### -------Simple simulated PCP problem-------#### # First we will simulate a simple dataset with the sim_data() function. # The dataset will be a 100x10 matrix comprised of: # 1. A rank-3 component as the ground truth L matrix; # 2. A ground truth sparse component S w/outliers in 1st & last entries; and # 3. A dense Gaussian noise component data <- sim_data() # Normally we would conduct grid search to tune eta. But, to keep the example # short, we will just use best parameters from the below grid search example: if (FALSE) { # \\dontrun{ eta_0 <- get_pcp_defaults(data$D)$eta eta_grid <- data.frame(\"eta\" = sort(c(0.1 * eta_0, eta_0 * seq(1, 10, 2))), \"r\" = 7) gs <- grid_search_cv(data$D, rrmc, eta_grid) gs$summary_stats } # } # The gs found the best rank to be 3, and the best eta to be 0.3 or 0.4, so # we will split the difference and use an eta of 0.35 pcp_model <- rrmc(data$D, r = 3, eta = 0.35) data.frame(   \"Observed_relative_error\" = norm(data$L - data$D, \"F\") / norm(data$L, \"F\"),   \"PCA_error\" = norm(data$L - proj_rank_r(data$D, r = 3), \"F\") / norm(data$L, \"F\"),   \"PCP_L_error\" = norm(data$L - pcp_model$L, \"F\") / norm(data$L, \"F\"),   \"PCP_S_error\" = norm(data$S - pcp_model$S, \"F\") / norm(data$S, \"F\") ) #>   Observed_relative_error PCA_error PCP_L_error PCP_S_error #> 1               0.1286753 0.0738434  0.03283472  0.04249677 # Results: # The grid search correctly found the rank (3) of the ground truth L matrix! # PCP outperformed PCA in it's recovery of the L matrix (even though we let # PCA \"cheat\" by telling PCA it was looking for a rank 3 solution)! # PCP successfully isolated the outlying event in S!"},{"path":"https://columbia-prime.github.io/pcpr/reference/hard_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Hard-thresholding operator — hard_threshold","title":"Hard-thresholding operator — hard_threshold","text":"hard_threshold() implements hard-thresholding operator given matrix D, making D sparser: elements D whose absolute value less given threshold thresh set 0, .e. \\(D[|D| < thresh] = 0\\). used non-convex PCP function rrmc() provide non-convex replacement prox_l1() method used convex PCP function root_pcp(). used iteratively model sparse S matrix help adaptive threshold (thresh changes course optimization).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/hard_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hard-thresholding operator — hard_threshold","text":"","code":"hard_threshold(D, thresh)"},{"path":"https://columbia-prime.github.io/pcpr/reference/hard_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hard-thresholding operator — hard_threshold","text":"D input data matrix. thresh scalar-valued hard-threshold acting D D[, j] = 0 abs(D[, j]) < thresh, D[, j] = D[, j] otherwise.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/hard_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hard-thresholding operator — hard_threshold","text":"hard-thresholded matrix.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/hard_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hard-thresholding operator — hard_threshold","text":"","code":"set.seed(42) D <- matrix(rnorm(25), 5, 5) S <- hard_threshold(D, thresh = 1) D #>            [,1]        [,2]       [,3]       [,4]       [,5] #> [1,]  1.3709584 -0.10612452  1.3048697  0.6359504 -0.3066386 #> [2,] -0.5646982  1.51152200  2.2866454 -0.2842529 -1.7813084 #> [3,]  0.3631284 -0.09465904 -1.3888607 -2.6564554 -0.1719174 #> [4,]  0.6328626  2.01842371 -0.2787888 -2.4404669  1.2146747 #> [5,]  0.4042683 -0.06271410 -0.1333213  1.3201133  1.8951935 S #>          [,1]     [,2]      [,3]      [,4]      [,5] #> [1,] 1.370958 0.000000  1.304870  0.000000  0.000000 #> [2,] 0.000000 1.511522  2.286645  0.000000 -1.781308 #> [3,] 0.000000 0.000000 -1.388861 -2.656455  0.000000 #> [4,] 0.000000 2.018424  0.000000 -2.440467  1.214675 #> [5,] 0.000000 0.000000  0.000000  1.320113  1.895193"},{"path":"https://columbia-prime.github.io/pcpr/reference/impute_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute missing values in given matrix — impute_matrix","title":"Impute missing values in given matrix — impute_matrix","text":"impute_matrix() imputes missing NA values given matrix using given imputation_scheme.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/impute_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute missing values in given matrix — impute_matrix","text":"","code":"impute_matrix(D, imputation_scheme)"},{"path":"https://columbia-prime.github.io/pcpr/reference/impute_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute missing values in given matrix — impute_matrix","text":"D input data matrix. imputation_scheme values replace missing NA values D . Can either: scalar numeric, indicating NA values imputed scalar numeric value; vector length ncol(D), signifying column-specific imputation, entry imputation_scheme vector corresponds imputation value column D; matrix dimension dim(D), indicating observation-specific imputation scheme, entry imputation_scheme matrix corresponds imputation value entry D.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/impute_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute missing values in given matrix — impute_matrix","text":"imputed matrix.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/impute_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute missing values in given matrix — impute_matrix","text":"","code":"####------------Imputation with a scalar------------#### # simulate a small 5x5 mixture D <- sim_data(5, 5)$D # corrupt the mixture with 40% missing observations D_tilde <- sim_na(D, 0.4)$D_tilde D_tilde #>           [,1]     [,2]     [,3]      [,4]     [,5] #> [1,]        NA 1.123878 1.052029 0.5437246       NA #> [2,] 1.6716886       NA 1.526285        NA 1.739935 #> [3,] 0.3776991 1.047751 1.969528        NA 1.058204 #> [4,]        NA 1.054244 1.029697 1.4755161 1.138653 #> [5,]        NA       NA       NA 0.6210926       NA # impute missing values with 0 impute_matrix(D_tilde, 0) #>           [,1]     [,2]     [,3]      [,4]     [,5] #> [1,] 0.0000000 1.123878 1.052029 0.5437246 0.000000 #> [2,] 1.6716886 0.000000 1.526285 0.0000000 1.739935 #> [3,] 0.3776991 1.047751 1.969528 0.0000000 1.058204 #> [4,] 0.0000000 1.054244 1.029697 1.4755161 1.138653 #> [5,] 0.0000000 0.000000 0.000000 0.6210926 0.000000 # impute missing values with -1 impute_matrix(D_tilde, -1) #>            [,1]      [,2]      [,3]       [,4]      [,5] #> [1,] -1.0000000  1.123878  1.052029  0.5437246 -1.000000 #> [2,]  1.6716886 -1.000000  1.526285 -1.0000000  1.739935 #> [3,]  0.3776991  1.047751  1.969528 -1.0000000  1.058204 #> [4,] -1.0000000  1.054244  1.029697  1.4755161  1.138653 #> [5,] -1.0000000 -1.000000 -1.000000  0.6210926 -1.000000  ####------------Imputation with a vector------------#### # impute missing values with the column-mean impute_matrix(D_tilde, apply(D_tilde, 2, mean, na.rm = TRUE)) #>           [,1]     [,2]     [,3]      [,4]     [,5] #> [1,] 1.0246939 1.123878 1.052029 0.5437246 1.312264 #> [2,] 1.6716886 1.075291 1.526285 0.8801111 1.739935 #> [3,] 0.3776991 1.047751 1.969528 0.8801111 1.058204 #> [4,] 1.0246939 1.054244 1.029697 1.4755161 1.138653 #> [5,] 1.0246939 1.075291 1.394385 0.6210926 1.312264 # impute missing values with the column-min impute_matrix(D_tilde, apply(D_tilde, 2, min, na.rm = TRUE)) #>           [,1]     [,2]     [,3]      [,4]     [,5] #> [1,] 0.3776991 1.123878 1.052029 0.5437246 1.058204 #> [2,] 1.6716886 1.047751 1.526285 0.5437246 1.739935 #> [3,] 0.3776991 1.047751 1.969528 0.5437246 1.058204 #> [4,] 0.3776991 1.054244 1.029697 1.4755161 1.138653 #> [5,] 0.3776991 1.047751 1.029697 0.6210926 1.058204  ####------------Imputation with a matrix------------#### # impute missing values with random Gaussian noise noise <- matrix(rnorm(prod(dim(D_tilde))), nrow(D_tilde), ncol(D_tilde)) impute_matrix(D_tilde, noise) #>             [,1]       [,2]      [,3]      [,4]       [,5] #> [1,] -0.09465904  1.1238777  1.052029 0.5437246 -1.7631631 #> [2,]  1.67168861 -0.2787888  1.526285 1.2146747  1.7399355 #> [3,]  0.37769915  1.0477507  1.969528 1.8951935  1.0582040 #> [4,]  1.30486965  1.0542439  1.029697 1.4755161  1.1386529 #> [5,]  2.28664539 -0.2842529 -1.781308 0.6210926  0.7048373  ####------------Imputation with LOD/sqrt(2)------------#### D <- sim_data(5, 5)$D lod_info <- sim_lod(D, q = 0.2) D_tilde <- lod_info$D_tilde D_tilde #>          [,1]     [,2]     [,3]      [,4]     [,5] #> [1,] 2.453301 1.123878 1.052029 0.5437246 1.357418 #> [2,] 1.671689 2.418877 1.526285 0.7718546 1.739935 #> [3,]       NA       NA 1.969528        NA       NA #> [4,] 1.331306 1.054244       NA 1.4755161 1.138653 #> [5,] 1.413282 1.212585 1.191888 0.6210926 2.284681 lod <- lod_info$lod impute_matrix(D_tilde, lod / sqrt(2)) #>           [,1]      [,2]      [,3]      [,4]     [,5] #> [1,] 2.4533007 1.1238777 1.0520287 0.5437246 1.357418 #> [2,] 1.6716886 2.4188773 1.5262852 0.7718546 1.739935 #> [3,] 0.8065153 0.7445447 1.9695275 0.3796034 0.793772 #> [4,] 1.3313064 1.0542439 0.7407385 1.4755161 1.138653 #> [5,] 1.4132823 1.2125850 1.1918875 0.6210926 2.284681"},{"path":"https://columbia-prime.github.io/pcpr/reference/loss_lod.html","id":null,"dir":"Reference","previous_headings":"","what":"Loss function for PCP's limit of detection penalty — loss_lod","title":"Loss function for PCP's limit of detection penalty — loss_lod","text":"loss_lod() includes LOD-specific penalty terms compute loss squared error term L + S - D.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/loss_lod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loss function for PCP's limit of detection penalty — loss_lod","text":"","code":"loss_lod(D, X, LOD)"},{"path":"https://columbia-prime.github.io/pcpr/reference/loss_lod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loss function for PCP's limit of detection penalty — loss_lod","text":"D original data matrix. X predicted value L + S current iteration. LOD LOD matrix, dim(LOD) == dim(D).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/loss_lod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loss function for PCP's limit of detection penalty — loss_lod","text":"Scalar value used calculate loss objective function.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/matrix_rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate rank of a given matrix — matrix_rank","title":"Estimate rank of a given matrix — matrix_rank","text":"matrix_rank() estimates rank given data matrix D counting number \"practically nonzero\" singular values D. rank matrix number linearly independent columns rows matrix, governing structure data. can intuitively thought number inherent latent patterns data. singular value \\(s\\) determined \"practically nonzero\" \\(s \\geq s_{max} \\cdot thresh\\), .e. greater equal maximum singular value D scaled given threshold thresh.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/matrix_rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate rank of a given matrix — matrix_rank","text":"","code":"matrix_rank(D, thresh = NULL)"},{"path":"https://columbia-prime.github.io/pcpr/reference/matrix_rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate rank of a given matrix — matrix_rank","text":"D input data matrix (NA values). thresh (Optional) double \\(> 0\\), specifying relative threshold \"practically zero\" determined, used calculate rank D. default, thresh = NULL, case threshold set max(dim(D)) * .Machine$double.eps.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/matrix_rank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate rank of a given matrix — matrix_rank","text":"integer estimating rank D.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/matrix_rank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate rank of a given matrix — matrix_rank","text":"","code":"data <- sim_data() matrix_rank(data$D) #> [1] 10 matrix_rank(data$L) #> [1] 3"},{"path":"https://columbia-prime.github.io/pcpr/reference/pcpr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"pcpr: Principal Component Pursuit for Environmental Epidemiology — pcpr-package","title":"pcpr: Principal Component Pursuit for Environmental Epidemiology — pcpr-package","text":"Implementation pattern recognition technique Principal Component Pursuit tailored environmental health data, described Gibson et al. (2022) doi:10.1289/EHP10479 .","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/pcpr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"pcpr: Principal Component Pursuit for Environmental Epidemiology — pcpr-package","text":"Maintainer: Lawrence G. Chillrud lawrencechillrud@gmail.com (ORCID) [copyright holder] Authors: Jaime Benavides (ORCID) Elizabeth . Gibson (ORCID) Junhui Zhang (ORCID) Jingkai Yan (ORCID) John N. Wright Jeff Goldsmith Marianthi-Anna Kioumourtzoglou (ORCID) contributors: Columbia University (00hj8s172) [funder]","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/proj_rank_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Project matrix to rank r — proj_rank_r","title":"Project matrix to rank r — proj_rank_r","text":"proj_rank_r() implements best (.e. closest) rank-r approximation input matrix. computed via simple truncated singular value decomposition (SVD), retaining first r leading singular values/vectors D. equivalent solving following optimization problem: \\(min ||X-D||_F s.t. rank(X) <= r\\), X approximated solution D input matrix. proj_rank_r() used iteratively model low-rank L matrix non-convex PCP function rrmc(), providing non-convex replacement prox_nuclear() method used convex PCP function root_pcp(). Intuitively, proj_rank_r() can also thought providing PCA estimate rank-r matrix L observed data D.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/proj_rank_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project matrix to rank r — proj_rank_r","text":"","code":"proj_rank_r(D, r)"},{"path":"https://columbia-prime.github.io/pcpr/reference/proj_rank_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project matrix to rank r — proj_rank_r","text":"D input data matrix (NA values). r rank D projected/truncated .","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/proj_rank_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project matrix to rank r — proj_rank_r","text":"best rank-r approximation D via truncated SVD.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/proj_rank_r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project matrix to rank r — proj_rank_r","text":"","code":"# Simulating a simple dataset D with the sim_data() function. # The dataset will be a 10x5 matrix comprised of: # 1. A rank-1 component as the ground truth L matrix; and # 2. A dense Gaussian noise component corrupting L, making L full-rank data <- sim_data(10, 5, 1, numeric(), 0.01) # The observed matrix D is full-rank, while L is rank-1: data.frame(\"D_rank\" = matrix_rank(data$D), \"L_rank\" = matrix_rank(data$L)) #>   D_rank L_rank #> 1      5      1 before_proj_err <- norm(data$D - data$L, \"F\") / norm(data$L, \"F\") # Projecting D onto the nearest rank-1 approximation, X, via proj_rank_r() X <- proj_rank_r(data$D, r = 1) after_proj_err <- norm(X - data$L, \"F\") / norm(data$L, \"F\") proj_v_obs_err <- norm(X - data$D, \"F\") / norm(data$D, \"F\") data.frame(   \"Observed_error\" = before_proj_err,   \"Projected_error\" = after_proj_err,   \"Projected_vs_observed_error\" = proj_v_obs_err ) #>   Observed_error Projected_error Projected_vs_observed_error #> 1      0.0283898      0.01435178                  0.02436504"},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_frobenius.html","id":null,"dir":"Reference","previous_headings":"","what":"Proximal gradient method for the Frobenius norm — prox_frobenius","title":"Proximal gradient method for the Frobenius norm — prox_frobenius","text":"prox_frobenius() implements proximal gradient method Frobenius norm. proximal gradient method used solve non-differentiable convex optimization problems. root_pcp(), thresholding minimizes square root sum squared error, error defined Z = D - L - S. internal function needed root_pcp(). expected users require access function.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_frobenius.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proximal gradient method for the Frobenius norm — prox_frobenius","text":"","code":"prox_frobenius(Z, c)"},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_frobenius.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proximal gradient method for the Frobenius norm — prox_frobenius","text":"Z input error/noise matrix, Z = D - L - S. c amount prox Frobenius method penalizes Z.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_frobenius.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proximal gradient method for the Frobenius norm — prox_frobenius","text":"thresholded error/noise matrix.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_l1.html","id":null,"dir":"Reference","previous_headings":"","what":"Proximal gradient method for the L1 norm — prox_l1","title":"Proximal gradient method for the L1 norm — prox_l1","text":"prox_l1() implements proximal gradient method L1 norm. root_pcp(), soft thresholding encourages S matrix sparse. proximal gradient method used solve non-differentiable convex optimization problems. internal function needed root_pcp(). expected users require access function.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_l1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proximal gradient method for the L1 norm — prox_l1","text":"","code":"prox_l1(S, c)"},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_l1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proximal gradient method for the L1 norm — prox_l1","text":"S input sparse matrix. c amount prox L1 method penalizes S.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_l1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proximal gradient method for the L1 norm — prox_l1","text":"thresholded sparse matrix.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_nuclear.html","id":null,"dir":"Reference","previous_headings":"","what":"Proximal gradient method for the nuclear norm — prox_nuclear","title":"Proximal gradient method for the nuclear norm — prox_nuclear","text":"prox_nuclear() implements proximal gradient method nuclear norm. nuclear norm equivalent L2 norm singular values matrix. singular value thresholding encourages low-rank L matrix low-rank root_pcp(). proximal gradient method used solve non-differentiable convex optimization problems. internal function needed root_pcp(). expected users require access function.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_nuclear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proximal gradient method for the nuclear norm — prox_nuclear","text":"","code":"prox_nuclear(L, c)"},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_nuclear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proximal gradient method for the nuclear norm — prox_nuclear","text":"L input low-rank matrix. c amount prox nuclear method penalizes L.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/prox_nuclear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proximal gradient method for the nuclear norm — prox_nuclear","text":"list containing: X: thresholded low-rank matrix. X_nuclear_norm: sum absolute values thresholded singular values (used objective function).","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":null,"dir":"Reference","previous_headings":"","what":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"dataset containing chemical concentrations (µg/m^3) 26 PM2.5 species measured every three six days 04/04/2001 12/30/2021 Queens, New York City. Data obtained U.S. Environmental Protection Agency's Air Quality System data mart (site ID: 36-081-0124).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"","code":"queens"},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"tibble 2443 rows 27 variables: Date: date PM2.5 measurements made ...: remaining 26 variables 26 PM2.5 species (µg/m^3): Al, NH4, , Ba, Br, Cd, Ca, Cl, Cr, Cu, EC, Fe, Pb, Mg, Mn, Ni, OC, K, Se, Si, Na, S, Ti, NO3, V, Zn","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"https://epa.maps.arcgis.com/apps/webappviewer/index.html?id=5f239fd3e72f424f98ef3d5def547eb5","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"US Environmental Protection Agency. Air Quality System Data Mart internet database available via https://www.epa.gov/outdoor-air-quality-data. Accessed July 15, 2022.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/queens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Daily chemical concentrations of 26 PM2.5 species from Queens, NYC (2001-2021) — queens","text":"","code":"queens #> # A tibble: 2,443 × 27 #>    Date            Al   NH4      As     Ba       Br     Cd      Ca      Cl #>    <date>       <dbl> <dbl>   <dbl>  <dbl>    <dbl>  <dbl>   <dbl>   <dbl> #>  1 2001-04-04 NA      1.62  NA      NA     NA       NA     NA      NA      #>  2 2001-04-07  0      2.66   0       0.012  0.00488  0      0.0401  0.0079 #>  3 2001-04-13  0.0094 1.41   0.0016  0.024  0.00211  0.004  0.036   0      #>  4 2001-04-19  0.0104 1.22   0.001   0.006  0.00422  0      0.0543  0.003  #>  5 2001-04-25  0.0172 0.723  0.0024  0.015  0.00117  0      0.0398  0      #>  6 2001-05-01  0.0384 3.48   0.0017  0.041  0.00873  0.001  0.136   0      #>  7 2001-05-04  0.0964 6.22   0.0025  0.039  0.0111   0      0.137   0      #>  8 2001-05-07  0.004  0.233  0.001   0.016  0.00263  0      0.055   0.0054 #>  9 2001-05-10  0.0547 2.04   0.001   0.055  0.00521  0      0.121   0.001  #> 10 2001-05-13  0.0215 0.229  0       0.021  0.00122  0      0.0249  0      #> # ℹ 2,433 more rows #> # ℹ 18 more variables: Cr <dbl>, Cu <dbl>, EC <dbl>, Fe <dbl>, Pb <dbl>, #> #   Mg <dbl>, Mn <dbl>, Ni <dbl>, OC <dbl>, K <dbl>, Se <dbl>, Si <dbl>, #> #   Na <dbl>, S <dbl>, Ti <dbl>, NO3 <dbl>, V <dbl>, Zn <dbl>"},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Square root principal component pursuit (convex PCP) — root_pcp","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"root_pcp() implements convex PCP algorithm \"Square root principal component pursuit\" described Zhang et al. (2021) , outfitted environmental health (EH)-specific extensions described Gibson et al. (2022). Given observed data matrix D, regularization parameters lambda mu, root_pcp() aims find best low-rank sparse estimates L S. L matrix encodes latent patterns govern observed data. S matrix captures extreme events data unexplained underlying patterns L. convex, root_pcp() determines rank r, number latent patterns data, autonomously optimization. , user need specify desired rank r output L matrix non-convex PCP model rrmc(). Experimentally, root_pcp() approach PCP modeling best able handle datasets governed well-defined underlying patterns, characterized quickly decaying singular values. typical imaging video data, uncommon EH data. observed data complex low rank structure (slowly decaying singular values), like EH data, rrmc() may offer better model estimate. Three EH-specific extensions currently supported root_pcp(): model can handle missing values input data matrix D; model can also handle measurements fall limit detection (LOD), provided LOD information user; model also equipped optional non-negativity constraint low-rank L matrix, ensuring output values L \\(> 0\\).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"","code":"root_pcp(   D,   lambda = NULL,   mu = NULL,   LOD = -Inf,   non_negative = TRUE,   max_iter = 10000,   verbose = FALSE )"},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"D input data matrix (can contain NA values). Note PCP converge much quickly D standardized way (e.g. scaling columns standard deviations, column-wise min-max normalization). lambda, mu (Optional) pair doubles range [0, Inf) regularizing S L. lambda controls sparsity output S matrix; larger values penalize non-zero entries S stringently, driving recovery sparser S matrices. mu adjusts model's sensitivity noise; larger values penalize errors predicted model observed data severely. highly recommended user tunes parameters using grid_search_cv() unique data matrix D. default, lambda mu NULL, case theoretically optimal values used, calculated according get_pcp_defaults(). LOD (Optional) limit detection (LOD) data. Entries D satisfy D >= LOD understood LOD, otherwise entries treated LOD. LOD can either: double, implying universal LOD common across measurements D; vector length ncol(D), signifying column-specific LOD, entry LOD vector corresponds LOD column D; matrix dimension dim(D), indicating observation-specific LOD, entry LOD matrix corresponds LOD entry D. default, LOD = -Inf, indicating known LODs PCP leverage. non_negative (Optional) logical indicating whether non-negativity constraint used constrain output L matrix entries \\(\\geq 0\\). default, non_negative = TRUE. max_iter (Optional) integer specifying maximum number iterations allow PCP giving meeting PCP's convergence criteria. default, max_iter = 10000, suitable problems. verbose (Optional) logical indicating whether print information real time course PCP's optimization. default, verbose = FALSE.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"list containing: L: rank-r low-rank matrix encoding r-many latent patterns governing observed input data matrix D. dim(L) dim(D). explicitly obtain underlying patterns, L can used input matrix factorization technique choice, e.g. PCA, factor analysis, non-negative matrix factorization. S: sparse matrix containing rare outlying extreme observations D explained underlying patterns corresponding L matrix. dim(S) dim(D). entries S 0, non-zero entries identify extreme outlying observations D. num_iter: number iterations taken reach convergence. num_iter == max_iter root_pcp() converge. objective: vector containing values root_pcp()'s objective function course optimization. converged: boolean indicating whether convergence criteria met max_iter reached.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"the-objective-function","dir":"Reference","previous_headings":"","what":"The objective function","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"root_pcp() optimizes following objective function: $$\\min_{L, S} ||L||_* + \\lambda ||S||_1 + \\mu ||L + S - D||_F$$ first term nuclear norm L matrix, incentivizing L low-rank. second term \\(\\ell_1\\) norm S matrix, encouraging S sparse. third term Frobenius norm applied model's noise, ensuring estimated low-rank sparse models L S together high fidelity observed data D. objective smooth differentiable, however convex separable. , optimized using Alternating Direction Method Multipliers (ADMM) algorithm Boyd et al. (2011), Gao et al. (2020).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"the-lambda-and-mu-parameters","dir":"Reference","previous_headings":"","what":"The lambda and mu parameters","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"lambda controls sparsity root_pcp()'s output S matrix; larger values lambda penalize non-zero entries S stringently, driving recovery sparser S matrices. Therefore, priori expect outlying events model, might expect grid search recover relatively larger lambda values, vice-versa. mu adjusts root_pcp()'s sensitivity noise; larger values mu penalize errors predicted model observed data (.e. noise), severely. Environmental data subject higher noise levels therefore require root_pcp() model equipped smaller mu values (since higher noise means greater discrepancy observed mixture true underlying low-rank sparse model). virtually noise-free settings (e.g. simulations), larger values mu appropriate. default values lambda mu offer theoretical guarantees optimal estimation performance, stable recovery L S. \"stable\", mean root_pcp()'s reconstruction error , worst case, proportional magnitude noise corrupting observed data (\\(||Z||_F\\)), often outperforming upper bound. Candès et al. (2011) obtained guarantee lambda, Zhang et al. (2021) obtained result mu.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"environmental-health-specific-extensions","dir":"Reference","previous_headings":"","what":"Environmental health specific extensions","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"refer interested readers Gibson et al. (2022) complete details regarding EH-specific extensions. Missing value functionality: PCP assumes data generating mechanisms govern missing observed entries D. PCP primarily seeks accurate estimation patterns rather individual observations, assumption reasonable, edge cases may always justified. Missing values D therefore reconstructed recovered low-rank L matrix according underlying patterns L. three corollaries keep mind regarding quality recovered missing observations: Recovery missing entries D relies accurate estimation L; fewer observations D, harder accurately reconstruct L (therefore estimation unobserved observed measurements L degrades); Greater proportions missingness D artifically drive sparsity estimated S matrix. possible recover sparse event S corresponding entry D unobserved. definition, sparse events S explained consistent patterns L. Practically, 20% entries D missing, least 20% entries S 0. Handling measurements limit detection: equipped LOD information, PCP treats estimations values known LOD equally valid approximations fall 0 LOD. course optimization, observations LOD pushed known range \\([0, LOD]\\) using penalties : \\(< LOD\\) estimate \\(< 0\\), stringently penalized, since measured observations negative. hand, \\(< LOD\\) estimate \\(>\\) LOD, also heavily penalized: less \\(< 0\\), observations known LOD, prior information observations must LOD. Observations known LOD penalized usual, using Frobenius norm objective function. Gibson et al. (2022) demonstrates experimental settings 50% data corrupted LOD, PCP LOD extension boasts superior accuracy recovered L models compared PCA coupled \\(LOD / \\sqrt{2}\\) imputation. PCP even outperforms PCA low-noise scenarios much 75% data corrupted LOD. situations PCA bettered PCP pathological cases D characterized extreme noise huge proportions (.e., 75%) observations falling LOD. non-negativity constraint L: enhance interpretability PCP-rendered solutions, optional non-negativity constraint can imposed L matrix ensure estimated values within \\(\\geq 0\\). prevents researchers deal negative observation values questions surrounding meaning utility. Non-negative L models also allow seamless use methods non-negative matrix factorization extract non-negative patterns. non-negativity constraint incorporated ADMM splitting technique via introduction additional optimization variable corresponding constraint.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"Zhang, Junhui, Jingkai Yan, John Wright. \"Square root principal component pursuit: tuning-free noisy robust matrix recovery.\" Advances Neural Information Processing Systems 34 (2021): 29464-29475. [available ] Gibson, Elizabeth ., Junhui Zhang, Jingkai Yan, Lawrence Chillrud, Jaime Benavides, Yanelli Nunez, Julie B. Herbstman, Jeff Goldsmith, John Wright, Marianthi-Anna Kioumourtzoglou. \"Principal component pursuit pattern identification environmental mixtures.\" Environmental Health Perspectives 130, . 11 (2022): 117008. Boyd, Stephen, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein. \"Distributed optimization statistical learning via alternating direction method multipliers.\" Foundations Trends Machine learning 3, . 1 (2011): 1-122. Gao, Wenbo, Donald Goldfarb, Frank E. Curtis. \"ADMM multiaffine constrained optimization.\" Optimization Methods Software 35, . 2 (2020): 257-303. Candès, Emmanuel J., Xiaodong Li, Yi Ma, John Wright. \"Robust principal component analysis?.\" Journal ACM (JACM) 58, . 3 (2011): 1-37.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/root_pcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Square root principal component pursuit (convex PCP) — root_pcp","text":"","code":"#### -------Simple simulated PCP problem-------#### # First we will simulate a simple dataset with the sim_data() function. # The dataset will be a 100x10 matrix comprised of: # 1. A rank-2 component as the ground truth L matrix; # 2. A ground truth sparse component S w/outliers along the diagonal; and # 3. A dense Gaussian noise component data <- sim_data(r = 2, sparse_nonzero_idxs = seq(1, 1000, 101), sigma = 0.1) # Normally we would conduct grid search to tune lambda and mu. But, to keep # the example short, we will just use best parameters found in the below grid # search example: if (FALSE) { # \\dontrun{ lambda_0 <- get_pcp_defaults(data$D)$lambda mu_0 <- get_pcp_defaults(data$D)$mu lambdas <- lambda_0 + seq(-0.05, 0.2, 0.025) mus <- mu_0 + seq(-1, 1, 0.3) params <- expand.grid(lambdas, mus) names(params) <- c(\"lambda\", \"mu\") gs <- grid_search_cv(data$D, root_pcp, params) dplyr::arrange(gs$summary_stats, rel_err) } # } # The gs found the best parameters to be lambda = 0.225 and mu = 3.04 pcp_model <- root_pcp(data$D, lambda = 0.225, mu = 3.04) data.frame(   \"Estimated_L_rank\" = matrix_rank(pcp_model$L, 5e-2),   \"Observed_relative_error\" = norm(data$L - data$D, \"F\") / norm(data$L, \"F\"),   \"PCA_error\" = norm(data$L - proj_rank_r(data$D, r = 2), \"F\") / norm(data$L, \"F\"),   \"PCP_L_error\" = norm(data$L - pcp_model$L, \"F\") / norm(data$L, \"F\"),   \"PCP_S_error\" = norm(data$S - pcp_model$S, \"F\") / norm(data$S, \"F\") ) #>   Estimated_L_rank Observed_relative_error PCA_error PCP_L_error PCP_S_error #> 1                2               0.2298567 0.1040869  0.09485763   0.2453499 # Results: # PCP found a rank 2 solution! # PCP outperformed PCA in it's recovery of the L matrix (even though we let # PCA \"cheat\" by telling PCA it was looking for a rank 2 solution)! # PCP successfully isolated the outlying events in S!"},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank-based robust matrix completion (non-convex PCP) — rrmc","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"rrmc() implements non-convex PCP algorithm \"Rank-based robust matrix completion\" described Cherapanamjeri et al. (2017) (see Algorithm 3), outfitted environmental health (EH)-specific extensions described Gibson et al. (2022). Given observed data matrix D, maximum rank search r, regularization parameter eta, rrmc() seeks find best low-rank sparse estimates L S using incremental rank-based strategy. L matrix encodes latent patterns govern observed data. S matrix captures extreme events data unexplained underlying patterns L. rrmc()'s incremental rank-based strategy first estimates rank-1 model \\((L^(1), S^(1))\\), using rank-1 model initialization point construct rank-2 model \\((L^(2), S^(2))\\), , desired rank-r model \\((L^(r), S^(r))\\) recovered. models ranks 1 r returned rrmc() way. Experimentally, rrmc() approach PCP best able handle datasets governed complex underlying patterns characterized slowly decaying singular values, EH data. observed data well-defined low rank structure (rapidly decaying singular values), root_pcp() may offer better model estimate. Two EH-specific extensions currently supported rrmc(): model can handle missing values input data matrix D; model can also handle measurements fall limit detection (LOD), provided LOD information user. Support non-negativity constraint rrmc()'s output added future release pcpr.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"","code":"rrmc(D, r, eta = NULL, LOD = -Inf)"},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"D input data matrix (can contain NA values). Note PCP converge much quickly D standardized way (e.g. scaling columns standard deviations, column-wise min-max normalization). r integer >= 1 specifying maximum rank PCP model return. models rank 1 r returned. eta (Optional) double range [0, Inf) defining ratio model's sensitivity sparse dense noise. Larger values eta place greater emphasis penalizing non-zero entries S penalizing dense noise Z, .e. errors predicted observed data Z = L + S - D. recommended tune eta using grid_search_cv() unique data matrix D. default, eta = NULL, case eta retrieved using get_pcp_defaults(). LOD (Optional) limit detection (LOD) data. Entries D satisfy D >= LOD understood LOD, otherwise entries treated LOD. LOD can either: double, implying universal LOD common across measurements D; vector length ncol(D), signifying column-specific LOD, entry LOD vector corresponds LOD column D; matrix dimension dim(D), indicating observation-specific LOD, entry LOD matrix corresponds LOD entry D. default, LOD = -Inf, indicating known LODs PCP leverage.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"list containing: L: rank-r low-rank matrix encoding r-many latent patterns governing observed input data matrix D. dim(L) dim(D). explicitly obtain underlying patterns, L can used input matrix factorization technique choice, e.g. PCA, factor analysis, non-negative matrix factorization. S: sparse matrix containing rare outlying extreme observations D explained underlying patterns corresponding L matrix. dim(S) dim(D). entries S 0, non-zero entries identify extreme outlying observations D. L_list: list r-many L matrices recovered course rrmc()'s iterative optimization procedure. first element L_list corresponds rank-1 L matrix, second rank-2 L matrix, . S_list: list r-many corresponding S matrices recovered course rrmc()'s iterative optimization procedure. first element S_list corresponds rank-1 solution's S matrix, second rank-2 solution's S matrix, . objective: vector containing values rrmc()'s objective function course optimization.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"the-objective-function","dir":"Reference","previous_headings":"","what":"The objective function","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"rrmc() implicitly optimizes following objective function: $$\\min_{L, S} I_{rank(L) \\leq r} + \\eta ||S||_0 + ||L + S - D||_F^2$$ first term indicator function checking L matrix strictly rank r less, implemented using rank r projection operator proj_rank_r(). second term \\(\\ell_0\\) norm applied S matrix encourage sparsity, implemented help adaptive hard-thresholding operator hard_threshold(). third term squared Frobenius norm applied model's noise.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"the-eta-parameter","dir":"Reference","previous_headings":"","what":"The eta parameter","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"eta parameter scales sparse penalty applied rrmc()'s output sparse S matrix. Larger values eta penalize non-zero entries S stringently, driving recovery sparser S matrices. parameters scaling terms rrmc()'s objective function, eta can intuitively thought dial balances model's sensitivity extreme events (placed S) sensitivity noise Z (captured last term objective, measures discrepancy predicted model observed data). Larger values eta place greater emphasis penalizing non-zero entries S penalizing errors predicted observed data Z = L + S - D.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"environmental-health-specific-extensions","dir":"Reference","previous_headings":"","what":"Environmental health specific extensions","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"refer interested readers Gibson et al. (2022) complete details regarding EH-specific extensions. Missing value functionality: PCP assumes data generating mechanisms govern missing observed entries D. PCP primarily seeks accurate estimation patterns rather individual observations, assumption reasonable, edge cases may always justified. Missing values D therefore reconstructed recovered low-rank L matrix according underlying patterns L. three corollaries keep mind regarding quality recovered missing observations: Recovery missing entries D relies accurate estimation L; fewer observations D, harder accurately reconstruct L (therefore estimation unobserved observed measurements L degrades); Greater proportions missingness D artifically drive sparsity estimated S matrix. possible recover sparse event S corresponding entry D unobserved. definition, sparse events S explained consistent patterns L. Practically, 20% entries D missing, least 20% entries S 0. Handling measurements limit detection: equipped LOD information, PCP treats estimations values known LOD equally valid approximations fall 0 LOD. course optimization, observations LOD pushed known range \\([0, LOD]\\) using penalties : \\(< LOD\\) estimate \\(< 0\\), stringently penalized, since measured observations negative. hand, \\(< LOD\\) estimate \\(>\\) LOD, also heavily penalized: less \\(< 0\\), observations known LOD, prior information observations must LOD. Observations known LOD penalized usual, using Frobenius norm objective function. Gibson et al. (2022) demonstrates experimental settings 50% data corrupted LOD, PCP LOD extension boasts superior accuracy recovered L models compared PCA coupled \\(LOD / \\sqrt{2}\\) imputation. PCP even outperforms PCA low-noise scenarios much 75% data corrupted LOD. situations PCA bettered PCP pathological cases D characterized extreme noise huge proportions (.e., 75%) observations falling LOD.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"Cherapanamjeri, Yeshwanth, Kartik Gupta, Prateek Jain. \"Nearly optimal robust matrix completion.\" International Conference Machine Learning. PMLR, 2017. [available ] Gibson, Elizabeth ., Junhui Zhang, Jingkai Yan, Lawrence Chillrud, Jaime Benavides, Yanelli Nunez, Julie B. Herbstman, Jeff Goldsmith, John Wright, Marianthi-Anna Kioumourtzoglou. \"Principal component pursuit pattern identification environmental mixtures.\" Environmental Health Perspectives 130, . 11 (2022): 117008.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/rrmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank-based robust matrix completion (non-convex PCP) — rrmc","text":"","code":"#### -------Simple simulated PCP problem-------#### # First we will simulate a simple dataset with the sim_data() function. # The dataset will be a 100x10 matrix comprised of: # 1. A rank-3 component as the ground truth L matrix; # 2. A ground truth sparse component S w/outliers in 1st & last entries; and # 3. A dense Gaussian noise component data <- sim_data() # Normally we would conduct grid search to tune eta. But, to keep the example # short, we will just use best parameters from the below grid search example: if (FALSE) { # \\dontrun{ eta_0 <- get_pcp_defaults(data$D)$eta eta_grid <- data.frame(\"eta\" = sort(c(0.1 * eta_0, eta_0 * seq(1, 10, 2))), \"r\" = 7) gs <- grid_search_cv(data$D, rrmc, eta_grid) dplyr::arrange(gs$summary_stats, rel_err) } # } # The gs found the best rank to be 3, and the best eta to be 0.3 or 0.4, so # we will split the difference and use an eta of 0.35 pcp_model <- rrmc(data$D, r = 3, eta = 0.35) data.frame(   \"Observed_relative_error\" = norm(data$L - data$D, \"F\") / norm(data$L, \"F\"),   \"PCA_error\" = norm(data$L - proj_rank_r(data$D, r = 3), \"F\") / norm(data$L, \"F\"),   \"PCP_L_error\" = norm(data$L - pcp_model$L, \"F\") / norm(data$L, \"F\"),   \"PCP_S_error\" = norm(data$S - pcp_model$S, \"F\") / norm(data$S, \"F\") ) #>   Observed_relative_error PCA_error PCP_L_error PCP_S_error #> 1               0.1286753 0.0738434  0.03283472  0.04249677 # Results: # The grid search correctly found the rank (3) of the ground truth L matrix! # PCP outperformed PCA in it's recovery of the L matrix (even though we let # PCA \"cheat\" by telling PCA it was looking for a rank 3 solution)! # PCP successfully isolated the outlying event in S!"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate simple mixtures data — sim_data","title":"Simulate simple mixtures data — sim_data","text":"sim_data() generates simulated dataset D = L + S + Z experimentation Principal Component Pursuit (PCP) algorithms.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate simple mixtures data — sim_data","text":"","code":"sim_data(   n = 100,   p = 10,   r = 3,   sparse_nonzero_idxs = NULL,   sigma = 0.05,   seed = 42 )"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate simple mixtures data — sim_data","text":"n, p (Optional) pair integers specifying simulated dataset's number n observations (rows) p variables (columns). default, n = 100, p = 10. r (Optional) integer specifying rank simulated dataset's low-rank component. Intuitively, number latent patterns governing simulated dataset. Must r <= min(n, p). default, r = 3. sparse_nonzero_idxs (Optional) integer vector length(sparse_nonzero_idxs) <= n * p specifying indices non-zero elements sparse component. default, sparse_nonzero_idxs = NULL, case defined vector seq(1, n * p, n + 1) (placing sparse noise along diagonal simulated dataset). sigma (Optional) double specifying standard deviation dense (Gaussian) noise component Z. default, sigma = 0.05. seed (Optional) integer specifying seed random number generation. default, seed = 42.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate simple mixtures data — sim_data","text":"list containing: D: observed data matrix, D = L + S + Z. L: ground truth rank-r low-rank matrix. S: ground truth sparse matrix. S: ground truth dense (Gaussian) noise matrix.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate simple mixtures data — sim_data","text":"data simulated follows: L <- matrix(runif(n * r), n, r) %*% matrix(runif(r * p), r, p) S <- matrix(0, n, p) S[sparse_nonzero_idxs] <- 1 Z <- matrix(rnorm(n * p, sd = sigma), n, p) D <- L + S + Z","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate simple mixtures data — sim_data","text":"","code":"# rank 3 example data <- sim_data() matrix_rank(data$D) #> [1] 10 matrix_rank(data$L) #> [1] 3 # rank 7 example data <- sim_data(n = 1000, p = 25, r = 7) matrix_rank(data$D) #> [1] 25 matrix_rank(data$L) #> [1] 7"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_lod.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate limit of detection data — sim_lod","title":"Simulate limit of detection data — sim_lod","text":"sim_lod() simulates putting columns given matrix D limit detection (LOD) calculating given quantile q column corrupting values < quantile NA, returning newly corrupted matrix, binary corruption mask, vector column LODs.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_lod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate limit of detection data — sim_lod","text":"","code":"sim_lod(D, q)"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_lod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate limit of detection data — sim_lod","text":"D input data matrix. q double range [0, 1] specifying quantile use creating column-wise LODs. Passed probs argument quantile() function.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_lod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate limit of detection data — sim_lod","text":"list containing: D_tilde: original matrix D corrupted < LOD NA values. tilde_mask: binary matrix dim(D) specifying locations corrupted entries (1) uncorrupted entries (0). lod: vector length(lod) == ncol(D) providing simulated LOD values corresponding column D_tilde.","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_lod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate limit of detection data — sim_lod","text":"","code":"D <- sim_data(5, 5, sigma = 0.8)$D D #>            [,1]      [,2]      [,3]      [,4]        [,5] #> [1,]  2.9302635 0.8938987 0.7291769 0.8853122  0.06966197 #> [2,]  1.4584989 1.0828959 1.3333332 1.3004826  1.15159124 #> [3,] -1.6146424 0.9188127 0.6471552 1.2856310  0.42002327 #> [4,] -0.4990438 1.9652499 1.3747700 1.0188214 -0.67200285 #> [5,]  2.4033674 2.6339801 0.7118914 0.9998089  2.31177279 sim_lod(D, q = 0.2) #> $D_tilde #>            [,1]      [,2]      [,3]      [,4]       [,5] #> [1,]  2.9302635        NA 0.7291769        NA 0.06966197 #> [2,]  1.4584989 1.0828959 1.3333332 1.3004826 1.15159124 #> [3,]         NA 0.9188127        NA 1.2856310 0.42002327 #> [4,] -0.4990438 1.9652499 1.3747700 1.0188214         NA #> [5,]  2.4033674 2.6339801 0.7118914 0.9998089 2.31177279 #>  #> $tilde_mask #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    1    0    1    0 #> [2,]    0    0    0    0    0 #> [3,]    1    0    1    0    0 #> [4,]    0    0    0    0    1 #> [5,]    0    0    0    0    0 #>  #> $lod #> [1] -0.72216355  0.91382991  0.69894415  0.97690956 -0.07867099 #>"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate random missingness in a given matrix — sim_na","title":"Simulate random missingness in a given matrix — sim_na","text":"sim_na() corrupts given data matrix D random perc percent entries set missing (set NA). Used grid_search_cv() constructing test matrices PCP models. Can used experimentation PCP models. Note: observed values can corrupted NA. means matrix D already e.g. 20% values missing, sim_na(D, perc = 0.2) result matrix 40% values missing. e.g. perc = 0.6 passed input D e.g. 10% entries left observed, remaining corruptable entries set NA.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate random missingness in a given matrix — sim_na","text":"","code":"sim_na(D, perc, seed = 42)"},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate random missingness in a given matrix — sim_na","text":"D input data matrix. perc double range [0, 1] specifying percentage entries D corrupt missing (NA). seed (Optional) integer specifying seed random selection entries D corrupt missing (NA). default, seed = 42.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate random missingness in a given matrix — sim_na","text":"list containing: D_tilde: original matrix D random perc percent entries set NA. tilde_mask: binary matrix dim(D) specifying locations corrupted entries (1) uncorrupted entries (0).","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/sim_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate random missingness in a given matrix — sim_na","text":"","code":"# Simple example corrupting 20% of a 5x5 matrix D <- matrix(1:25, 5, 5) corrupted_data <- sim_na(D, perc = 0.2) corrupted_data$D_tilde #>      [,1] [,2] [,3] [,4] [,5] #> [1,]   NA    6   11   16   21 #> [2,]    2    7   12   NA   22 #> [3,]    3    8   13   18   23 #> [4,]   NA    9   14   19   24 #> [5,]   NA   NA   15   20   25 sum(is.na(corrupted_data$D_tilde)) / prod(dim(corrupted_data$D_tilde)) #> [1] 0.2 # Now corrupting another 20% ontop of the original 20% double_corrupted <- sim_na(corrupted_data$D_tilde, perc = 0.2) double_corrupted$D_tilde #>      [,1] [,2] [,3] [,4] [,5] #> [1,]   NA    6   11   16   21 #> [2,]   NA   NA   12   NA   NA #> [3,]    3   NA   13   18   23 #> [4,]   NA    9   NA   19   24 #> [5,]   NA   NA   15   20   25 sum(is.na(double_corrupted$D_tilde)) / prod(dim(double_corrupted$D_tilde)) #> [1] 0.4 # Corrupting the remaining entries by passing in a large value for perc all_corrupted <- sim_na(double_corrupted$D_tilde, perc = 1) all_corrupted$D_tilde #>      [,1] [,2] [,3] [,4] [,5] #> [1,]   NA   NA   NA   NA   NA #> [2,]   NA   NA   NA   NA   NA #> [3,]   NA   NA   NA   NA   NA #> [4,]   NA   NA   NA   NA   NA #> [5,]   NA   NA   NA   NA   NA"},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute singular values of given matrix — sing","title":"Compute singular values of given matrix — sing","text":"sing() calculates singular values given data matrix D. done call svd(), included pcpr enable quick characterization data matrix's raw low-rank structure, help decide whether rrmc() root_pcp() appropriate PCP algorithm employ conjunction D. Experimentally, rrmc() approach PCP best able handle datasets governed complex underlying patterns characterized slowly decaying singular values, EH data. observed data well-defined low rank structure (rapidly decaying singular values), root_pcp() may offer better model estimate.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute singular values of given matrix — sing","text":"","code":"sing(D)"},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute singular values of given matrix — sing","text":"D input data matrix (NA values).","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute singular values of given matrix — sing","text":"numeric vector containing singular values D.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute singular values of given matrix — sing","text":"\"Singular value decomposition\" Wikipedia article.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute singular values of given matrix — sing","text":"","code":"data <- sim_data() sing(data$D) #>  [1] 27.6008592  3.0491717  2.2919038  1.2200243  1.2007841  1.1485292 #>  [7]  1.1082292  1.0574525  0.9880939  0.9487314 # could plot the singular values for visual inspection with e.g. # plot(sing(data$D), type = 'b')"},{"path":"https://columbia-prime.github.io/pcpr/reference/sparsity.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate sparsity of given matrix — sparsity","title":"Estimate sparsity of given matrix — sparsity","text":"sparsity() estimates percentage entries given data matrix D whose values \"practically zero\". absolute value entry given threshold parameter thresh, value determined \"practically zero\", increasing estimated sparsity D. Note NA values imputed 0 sparsity calculation made.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sparsity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate sparsity of given matrix — sparsity","text":"","code":"sparsity(D, thresh = 1e-04)"},{"path":"https://columbia-prime.github.io/pcpr/reference/sparsity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate sparsity of given matrix — sparsity","text":"D input data matrix. thresh (Optional) numeric threshold >= 0 used determine entry D \"practically zero\". absolute value entry thresh, judged \"practically zero\". default, thresh = 1e-04.","code":""},{"path":"https://columbia-prime.github.io/pcpr/reference/sparsity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate sparsity of given matrix — sparsity","text":"sparsity D, measured percentage entries D \"practically zero\".","code":""},{"path":[]},{"path":"https://columbia-prime.github.io/pcpr/reference/sparsity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate sparsity of given matrix — sparsity","text":"","code":"sparsity(matrix(rep(c(1, 0), 8), 4, 4)) #> [1] 0.5 sparsity(matrix(0:8, 3, 3)) #> [1] 0.1111111 sparsity(matrix(0, 3, 3)) #> [1] 1"},{"path":"https://columbia-prime.github.io/pcpr/news/index.html","id":"pcpr-100","dir":"Changelog","previous_headings":"","what":"pcpr 1.0.0","title":"pcpr 1.0.0","text":"Initial CRAN submission.","code":""}]
